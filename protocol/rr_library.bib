
@article{allee2018,
  title = {Disclosure "{{Scriptability}}"},
  volume = {56},
  issn = {0021-8456},
  abstract = {In response to the increasing use of computer programs to process firm disclosures, this registered report develops a new measure of scriptability that reflects computerized, rather than human, information processing costs. We validate our measure using SEC filing-derived data from prior research and identify firm and disclosure characteristics related to it. In our planned hypothesis tests, we find some evidence that the speed of the market response to filings increases with scriptability, but find little evidence that scriptability affects the incidence and speed of news dissemination by Dow Jones. In additional analyses, we find that scriptability exhibits both positive and negative associations with changes in information asymmetry between market participants, depending on the filing, trading window, and measure examined. We also find little evidence that XBRL interacts with scriptability in a meaningful way. Overall, our study broadens our understanding of information processing costs and provides opportunities for new avenues of research.},
  language = {English},
  number = {2},
  journal = {Journal of Accounting Research},
  doi = {10.1111/1475-679x.12203},
  author = {Allee, Kristian D. and Deangelis, Matthew D. and Moon, James R.},
  month = may,
  year = {2018},
  keywords = {include,note},
  pages = {363-430},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7XHDMCYS\\Allee et al. - 2018 - Disclosure Scriptability.pdf},
  note = {WOS:000430467200002}
}

@article{allen2019,
  title = {Open Science Challenges, Benefits and Tips in Early Career and Beyond},
  volume = {17},
  issn = {1544-9173},
  abstract = {The movement towards open science is a consequence of seemingly pervasive failures to replicate previous research. This transition comes with great benefits but also significant challenges that are likely to affect those who carry out the research, usually early career researchers (ECRs). Here, we describe key benefits, including reputational gains, increased chances of publication, and a broader increase in the reliability of research. The increased chances of publication are supported by exploratory analyses indicating null findings are substantially more likely to be published via open registered reports in comparison to more conventional methods. These benefits are balanced by challenges that we have encountered and that involve increased costs in terms of flexibility, time, and issues with the current incentive structure, all of which seem to affect ECRs acutely. Although there are major obstacles to the early adoption of open science, overall open science practices should benefit both the ECR and improve the quality of research. We review 3 benefits and 3 challenges and provide suggestions from the perspective of ECRs for moving towards open science practices, which we believe scientists and institutions at all levels would do well to consider.},
  language = {English},
  number = {5},
  journal = {Plos Biology},
  doi = {10.1371/journal.pbio.3000246},
  author = {Allen, Christopher and Mehler, David M. A.},
  month = may,
  year = {2019},
  keywords = {empirical,include,RRs},
  pages = {e3000246},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\NTBBHPV3\\Allen and Mehler - 2019 - Open science challenges, benefits and tips in earl.pdf},
  note = {WOS:000470189800010}
}

@article{anonymous2013,
  title = {Registered {{Reports}} and {{Replications}} in {{Attention}}, {{Perception}}, \& {{Psychophysics}}},
  volume = {75},
  issn = {1943-3921},
  language = {English},
  number = {5},
  journal = {Attention Perception \& Psychophysics},
  doi = {10.3758/s13414-013-0502-5},
  author = {Anonymous},
  month = jul,
  year = {2013},
  keywords = {psychology,failure,include,announcement_RRs,note},
  pages = {781-783},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\TVEPZHEM\\Anonymous - 2013 - Registered Reports and Replications in Attention, .pdf},
  note = {WOS:000322668000001}
}

@article{anonymous2017,
  title = {Promoting Reproducibility with Registered Reports},
  volume = {1},
  issn = {2397-3374},
  language = {English},
  number = {1},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-016-0034},
  author = {Anonymous},
  month = jan,
  year = {2017},
  keywords = {include,announcement_RRs,note},
  pages = {UNSP 0034},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\YEUFNEY9\\Anonymous - 2017 - Promoting reproducibility with registered reports.pdf},
  note = {WOS:000418775900002}
}

@article{anonymous2019,
  title = {What Science Looks Like},
  volume = {3},
  issn = {2397-3374},
  abstract = {The publication of our first two Registered Reports marks a major milestone for Nature Human Behaviour. These studies demonstrate what many researchers know, but is often hidden from the published literature: confirmatory research doesn't always confirm the authors' hypotheses.},
  language = {English},
  number = {8},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-019-0652-0},
  author = {Anonymous},
  month = aug,
  year = {2019},
  keywords = {include,RRs,empirical_case_study,note},
  pages = {763-763},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\IBQRH9RX\\Anonymous - 2019 - What science looks like.pdf},
  note = {WOS:000480445500001}
}

@article{ansari2018,
  title = {Registered {{Reports}}: Introducing a New Article Format in {{Developmental Science}}},
  volume = {21},
  issn = {1363-755X},
  language = {English},
  number = {1},
  journal = {Developmental Science},
  doi = {10.1111/desc.12650},
  author = {Ansari, Daniel and Gervain, Judit},
  month = jan,
  year = {2018},
  keywords = {announcement_RRs,include_key_has_critique},
  pages = {e12650},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\FQNUSUKU\\Ansari and Gervain - 2018 - Registered Reports introducing a new article form.pdf},
  note = {WOS:000418865300021}
}

@article{back2018,
  title = {Continued {{Quality}}, {{Openness}}, and {{Curiosity}} at the {{European Journal}} of {{Personality}}},
  volume = {32},
  issn = {0890-2070},
  language = {English},
  number = {1},
  journal = {European Journal of Personality},
  doi = {10.1002/per.2141},
  author = {Back, Mitja D.},
  year = {JAN-FEB 2018},
  keywords = {registered-reports,include,note},
  pages = {3-5},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\LDT3RU65\\Back - 2018 - Continued Quality, Openness, and Curiosity at the .pdf},
  note = {WOS:000425082900001}
}

@article{bernard2018,
  title = {Editorial: {{Introducing Registered Reports}}},
  volume = {5},
  issn = {2373-2822},
  language = {English},
  number = {2},
  journal = {Eneuro},
  doi = {10.1523/eneuro.0089-18.2018},
  author = {Bernard, Christophe},
  year = {MAR-APR 2018},
  keywords = {include,announcement_RRs,note},
  pages = {UNSP e0089-18.2018},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\HAII9IS8\\Bernard - 2018 - Editorial Introducing Registered Reports.pdf},
  note = {WOS:000430017100011}
}

@article{bloomfield2018,
  title = {No {{System Is Perfect}}: {{Understanding How Registration}}-{{Based Editorial Processes Affect Reproducibility}} and {{Investment}} in {{Research Quality}}},
  volume = {56},
  issn = {0021-8456},
  abstract = {The papers in this volume were published through a Registration-based Editorial Process (REP). Authors submitted proposals to gather and analyze data; successful proposals were guaranteed publication as long as the authors lived up to their commitments, regardless of whether results supported their predictions. To understand how REP differs from the Traditional Editorial Process (TEP), we analyze the papers themselves; conference comments; a survey of conference authors, reviewers, and attendees; and a survey of authors who have successfully published under TEP. We find that REP increases up-front investment in planning, data gathering, and analysis, but reduces follow-up investment after results are known. This shift in investment makes individual results more reproducible, but leaves articles less thorough and refined. REP could be improved by encouraging selected forms of follow-up investment that survey respondents believe are usually used under TEP to make papers more informative, focused, and accurate at little risk of overstatement.},
  language = {English},
  number = {2},
  journal = {Journal of Accounting Research},
  doi = {10.1111/1475-679x.12208},
  author = {Bloomfield, Robert and Rennekamp, Kristina and Steenhoven, Blake},
  month = may,
  year = {2018},
  keywords = {empirical,include_key},
  pages = {313-362},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\3IGBRAJP\\Bloomfield et al. - 2018 - No System Is Perfect Understanding How Registrati.pdf},
  note = {WOS:000430467200001}
}

@article{bowman2018,
  title = {A {{Layered Framework}} for {{Considering Open Science Practices}}},
  volume = {35},
  issn = {0882-4096},
  abstract = {The open science movement, although not new to social science broadly, has gained momentum recently within communication science. In response, journals in our field have begun encouraging open science practices, from data and materials sharing to submitting preregistered research reports. However, this momentum has also led to some confusion over what is and is not considered open science and what the value of open sciences practices is. In this editorial we lay out an "onion model" of open science that describes increasing levels of transparency and suggests howopen science practices can be understood less as a revolutionary concept but more as a logical extension of some of the historical pillars of scientific norms. Through this model, we provide tangible steps for how scholarsmay begin thinking about how to introduce open science practices into their current and future empirical efforts.},
  language = {English},
  number = {4},
  journal = {Communication Research Reports},
  doi = {10.1080/08824096.2018.1513273},
  author = {Bowman, Nicholas David and Keene, Justin Robert},
  year = {2018},
  keywords = {Transparency,Open Science,Preregistered Reports,Research Ethics,include,note},
  pages = {363-372},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\ZVQYFS8H\\Bowman and Keene - 2018 - A Layered Framework for Considering Open Science P.pdf},
  note = {WOS:000445736200008}
}

@article{campbell2018,
  title = {Conditional Equivalence Testing: {{An}} Alternative Remedy for Publication Bias},
  volume = {13},
  issn = {1932-6203},
  abstract = {We introduce a publication policy that incorporates "conditional equivalence testing" (CET), a two-stage testing scheme in which standard NHST is followed conditionally by testing for equivalence. The idea of CET is carefully considered as it has the potential to address recent concerns about reproducibility and the limited publication of null results. In this paper we detail the implementation of CET, investigate similarities with a Bayesian testing scheme, and outline the basis for how a scientific journal could proceed to reduce publication bias while remaining relevant.},
  language = {English},
  number = {4},
  journal = {Plos One},
  doi = {10.1371/journal.pone.0195145},
  author = {Campbell, Harlan and Gustafson, Paul},
  month = apr,
  year = {2018},
  keywords = {include_key_critique},
  pages = {e0195145},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\IXZIJ62Y\\Campbell and Gustafson - 2018 - Conditional equivalence testing An alternative re.pdf},
  note = {WOS:000430026900018}
}

@article{chambers2015,
  title = {{{TEN REASONS WHY JOURNALS MUST REVIEW MANUSCRIPTS BEFORE RESULTS ARE KNOWN}}},
  volume = {110},
  issn = {0965-2140},
  language = {English},
  number = {1},
  journal = {Addiction},
  doi = {10.1111/add.12728},
  author = {Chambers, Christopher D.},
  month = jan,
  year = {2015},
  keywords = {reproducibility,publication bias,incentives,False positives,questionable research practices,registered reports,registered-reports,truth,study pre-registration,include,note},
  pages = {10-11},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\MZQC4AJU\\Chambers - 2015 - TEN REASONS WHY JOURNALS MUST REVIEW MANUSCRIPTS B.pdf},
  note = {WOS:000346699700004}
}

@article{chambers2017,
  title = {Registered Reports at the {{European Journal}} of {{Neuroscience}}: Consolidating and Extending Peer-Reviewed Study Pre-Registration},
  volume = {45},
  issn = {0953-816X},
  language = {English},
  number = {5},
  journal = {European Journal of Neuroscience},
  doi = {10.1111/ejn.13519},
  author = {Chambers, Christopher D. and Forstmann, Birte and Pruszynski, J. Andrew},
  month = mar,
  year = {2017},
  keywords = {incentives,editorial,truth,include,note},
  pages = {627-628},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\TRBI9FBC\\Chambers et al. - 2017 - Registered reports at the European Journal of Neur.pdf},
  note = {WOS:000398518300001}
}

@article{chambers2019,
  title = {Science in Flux: {{Registered}} Reports and beyond at the {{European Journal}} of {{Neuroscience}}},
  volume = {49},
  issn = {0953-816X},
  language = {English},
  number = {1},
  journal = {European Journal of Neuroscience},
  doi = {10.1111/ejn.14319},
  author = {Chambers, Christopher D. and Forstmann, Birte and Pruszynski, J. Andrew},
  month = jan,
  year = {2019},
  keywords = {editorial,include,note},
  pages = {4-5},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\6JZX4MME\\Chambers et al. - 2019 - Science in flux Registered reports and beyond at .pdf},
  note = {WOS:000456800400002}
}

@article{chambers2018,
  title = {Protocol Transparency Is Vital for Registered Reports},
  volume = {2},
  issn = {2397-3374},
  language = {English},
  number = {11},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-018-0449-6},
  author = {Chambers, Christopher D. and Mellor, David T.},
  month = nov,
  year = {2018},
  keywords = {empirical,include_key,response_hardwicke2018},
  pages = {791-792},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\VLKEYLNP\\Chambers and Mellor - 2018 - Protocol transparency is vital for registered repo.pdf},
  note = {WOS:000449539900002}
}

@article{cook2016,
  title = {Reforms in {{Academic Publishing}}: {{Should Behavioral Disorders}} and {{Special Education Journals Embrace Them}}?},
  volume = {41},
  issn = {0198-7429},
  abstract = {Bias poses a significant threat to the validity of research findings as well as practices and policies based on research. Reforms to academic publishing have been proposed and implemented in other fields to address bias in research. In this paper I review some sources of bias in research, some proposed areas of reform in academic publishing (e.g., disclosure, open data and methods, preregistration, methodological guidelines for reviewers, registered reports, open review), and some potential problems associated with the reforms (e.g., limited empirical support, additional time and effort associated with implementation, placing journals at a competitive disadvantage, researchers relinquishing control of their data). I conclude with some thoughts to frame decisions on whether and how Behavioral Disorders and other special education journals might adopt reforms to academic publishing.},
  language = {English},
  number = {3},
  journal = {Behavioral Disorders},
  doi = {10.17988/0198-7429-41.3.161},
  author = {Cook, Bryan G.},
  month = may,
  year = {2016},
  keywords = {replication,publication bias,psychology,credibility,file drawer,registered reports,randomized controlled-trials,social-sciences,post,science research,include,note},
  pages = {161-172},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\AIDZ9SAA\\Cook - 2016 - Reforms in Academic Publishing Should Behavioral .pdf},
  note = {WOS:000388614600003}
}

@article{cook2018,
  title = {Promoting {{Open Science}} to {{Increase}} the {{Trustworthiness}} of {{Evidence}} in {{Special Education}}},
  volume = {85},
  issn = {0014-4029},
  abstract = {Scientific evidence should guide the selection of practice for individuals with disabilities. Scientific evidence, however, must be trustworthy to move special education toward greater empirical certainty and more effective policies and practices. Transparency, openness, and reproducibility increase the trustworthiness of evidence. We propose that researchers in special education adopt emerging open-science reforms, such as preprints, data and materials sharing, preregistration of studies and analysis plans, and Registered Reports. Adoption of these practices will require shifts in cultural norms, guidelines, and incentives. We discuss how adopting open-science practices can advance the quality of research and, consequently, policy and practice in special education.},
  language = {English},
  number = {1},
  journal = {Exceptional Children},
  doi = {10.1177/0014402918793138},
  author = {Cook, Bryan G. and Lloyd, John Wills and Mellor, David and Nosek, Brian A. and Therrien, William J.},
  month = oct,
  year = {2018},
  keywords = {replication,publication bias,replicability,incentives,registered reports,intervention,file   drawer,instruction,learning-disabilities,null,include,note},
  pages = {104-118},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\2TY6A24D\\Cook et al. - 2018 - Promoting Open Science to Increase the Trustworthi.pdf},
  note = {WOS:000446100000007}
}

@article{anonymous2018a,
  title = {What next for Registered Reports},
  volume = {2},
  issn = {2397-3374},
  language = {English},
  number = {11},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-018-0477-2},
  author = {Anonymous},
  month = nov,
  year = {2018},
  keywords = {include_key,empirical_annecdotal,rejection_reasons_RRs,requested_revisions_RRs},
  pages = {789-+},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\8F3AYT6D\\Anonymous - 2018 - What next for registered reports.pdf},
  note = {WOS:000449539900001}
}

@article{attwood2016,
  title = {Navigating an Open Road},
  volume = {70},
  issn = {0895-4356},
  language = {English},
  journal = {Journal of Clinical Epidemiology},
  doi = {10.1016/j.jclinepi.2015.04.016},
  author = {Attwood, Angela S. and Munafo, Marcus R.},
  month = feb,
  year = {2016},
  keywords = {registered-reports,include,note},
  pages = {264-266},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\5BZKBKVG\\Attwood and Munafo - 2016 - Navigating an open road.pdf},
  note = {WOS:000370676900033}
}

@article{baxter2017,
  title = {Promoting {{Transparency}} and {{Reproducibility}} in {{Behavioral Neuroscience}}: {{Publishing Replications}}, {{Registered Reports}}, and {{Null Results}}},
  volume = {131},
  issn = {0735-7044},
  abstract = {The editors of Behavioral Neuroscience have been discussing several recent developments in the landscape of scientific publishing. The discussion was prompted, in part, by reported issues of reproducibility and concerns about the integrity of the scientific literature. Although enhanced rigor and transparency in science are certainly important, a related issue is that increased competition and focus on novel findings has impeded the extent to which the scientific process is cumulative. We have decided to join the growing number of journals that are adopting new reviewing and publishing practices to address these problems. In addition to our standard research articles, we are pleased to announce 3 new categories of articles: replications, registered reports, and null results. In joining other journals in psychology and related fields to offer these publication types, we hope to promote higher standards of methodological rigor in our science. This will ensure that our discoveries are based on sound evidence and that they provide a durable foundation for future progress.},
  language = {English},
  number = {4},
  journal = {Behavioral Neuroscience},
  doi = {10.1037/bne0000207},
  author = {Baxter, Mark G. and Burwell, Rebecca D.},
  month = aug,
  year = {2017},
  keywords = {publication bias,p-hacking,HARKing,negative results,scientific   method,include,announcement_RRs,note,mpte},
  pages = {275-276},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\HZYSQTD6\\Baxter and Burwell - 2017 - Promoting Transparency and Reproducibility in Beha.pdf},
  note = {WOS:000405584700001}
}

@article{benning2019,
  title = {The {{Registration Continuum}} in {{Clinical Science}}: {{A Guide Toward Transparent Practices}}},
  volume = {128},
  issn = {0021-843X},
  abstract = {Clinical scientists can use a continuum of registration efforts that vary in their disclosure and timing relative to data collection and analysis. Broadly speaking, registration benefits investigators by offering stronger, more powerful tests of theory with particular methods in tandem with better control of long-run false positive error rates. Registration helps clinical researchers in thinking through tensions between bandwidth and fidelity that surround recruiting participants, defining clinical phenotypes, handling comorbidity, treating missing data. and analyzing rich and complex data. In particular. registration helps record and justify the reasons behind specific study design decisions, though it also provides the opportunity to register entire decision trees with specific endpoints. Creating ever more faithful registrations and standard operating procedures may offer alternative methods of judging a clinical investigator's scientific skill and eminence because study registration increases the transparency of clinical researchers' work.},
  language = {English},
  number = {6},
  journal = {Journal of Abnormal Psychology},
  doi = {10.1037/abn0000451},
  author = {Benning, Stephen D. and Bachrach, Rachel L. and Smith, Edward A. and Freeman, Andrew J. and Wright, Aidan G. C.},
  month = aug,
  year = {2019},
  keywords = {transparency,preregistration,credibility,disorders,registered-reports,coregistration,flexibility,framework,postregistration,psychopathology,symptoms,include,note},
  pages = {528-540},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\4SGX52R2\\Benning et al. - 2019 - The Registration Continuum in Clinical Science A .pdf},
  note = {WOS:000478024300006}
}

@article{byington2017,
  title = {Solutions to the {{Credibility Crisis}} in {{Management Science}}},
  volume = {16},
  issn = {1537-260X},
  abstract = {We argue that much academic misconduct can be explained as the result of social dilemmas occurring at two levels of management science. First, the career benefits associated with engaging in noncredible research practices (NCRPs; e.g., data manipulation, fabricating results, data hoarding, undisclosed HARKing) result in many academics choosing self-interest over collective welfare. These perverse incentives derive from journal gatekeepers who are pressed into a similar social dilemma; namely, an individual journal's status (i.e., its "impact factor") is likely to suffer from unilaterally implementing practices that help ensure the credibility of management science claims (e.g., dedicating journal space to strict replications, crowd-sourcing replications, data-submission requirements, in-house analysis checks, registered reports, Open Practice badges). Fortunately, research on social dilemmas and collective action offers solutions. For example, journal editors could pledge to publish a certain number of credibility boosting articles contingent on a proportion of their "peer" journals doing the same. Details for successful implementation of conditional pledges, other social dilemma solutions-including actions for management academics who support changes in journal practices (e.g., reviewer boycotts/buycotts), and insights on credibility-supportive journal practices from other fields-are provided.},
  language = {English},
  number = {1},
  journal = {Academy of Management Learning \& Education},
  doi = {10.5465/amle.2015.0035},
  author = {Byington, Eliza K. and Felps, Will},
  month = mar,
  year = {2017},
  keywords = {replication,communication,publication bias,psychology,cooperation,consequences,organizational sciences,scientific literature,social dilemmas,strategic management,include,note},
  pages = {142-162},
  note = {WOS:000398905600010}
}

@article{chambers2019a,
  title = {What's next for {{Registered Reports}}?},
  volume = {573},
  issn = {0028-0836},
  language = {English},
  number = {7773},
  journal = {Nature},
  doi = {10.1038/d41586-019-02674-6},
  author = {Chambers, Chris},
  month = sep,
  year = {2019},
  keywords = {include_key,funder_rr_partnerships,empirical_annecdotal,history_RRs},
  pages = {187-189},
  note = {WOS:000485415400029}
}

@article{chambers2013,
  title = {Registered {{Reports}}: {{A}} New Publishing Initiative at {{Cortex}}},
  volume = {49},
  issn = {0010-9452},
  language = {English},
  number = {3},
  journal = {Cortex},
  doi = {10.1016/j.cortex.2012.12.016},
  author = {Chambers, Christopher D.},
  month = mar,
  year = {2013},
  keywords = {incentives,truth,prevalence,include,note},
  pages = {609-610},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7LRNF92M\\Chambers - 2013 - Registered Reports A new publishing initiative at.pdf},
  note = {WOS:000317322900001}
}

@article{chambers2015a,
  title = {Registered {{Reports}}: {{Realigning}} Incentives in Scientific Publishing},
  volume = {66},
  issn = {0010-9452},
  language = {English},
  journal = {Cortex},
  doi = {10.1016/j.cortex.2015.03.022},
  author = {Chambers, Christopher D. and Dienes, Zoltan and McIntosh, Robert D. and Rotshtein, Pia and Willmes, Klaus},
  month = may,
  year = {2015},
  keywords = {statistical power,truth,psychological-research,include,note},
  pages = {A1-A2},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\4S4GR6RY\\Chambers et al. - 2015 - Registered Reports Realigning incentives in scien.pdf},
  note = {WOS:000354156500023}
}

@article{cropley2018,
  title = {Research as {{Artisanship}} versus {{Research}} as {{Generation}} of {{Novelty}}: {{The March}} to {{Nowhere}}},
  volume = {30},
  issn = {1040-0419},
  abstract = {The desire to ensure that its findings stand up to scrutiny is leading to a redefinition of research as skilled application of special techniques rather than a search for fresh insights. Generating novelty is now being seen as dangerous, because it could lead to false conclusions and loss of public confidence. The remedy is said to be replicability. However, replicability is not the goal of research, but a criterion for testing the robustness of novel ideas. The real problem is not excessive focus on novelty, but the poor quality of public dissemination of research findings. Thus, what is needed are public education and a responsible role for the media in informing the public, not the self-imposition of stifling orthodoxy on research.},
  language = {English},
  number = {4},
  journal = {Creativity Research Journal},
  doi = {10.1080/10400419.2018.1500190},
  author = {Cropley, Arthur},
  year = {2018},
  keywords = {include_key_critique},
  pages = {323-328},
  note = {ZSCC: 0000000 
WOS:000453358000001}
}

@article{davies2018,
  title = {{{ACP}} to Publish {{Registered Reports}}},
  volume = {32},
  issn = {0888-4080},
  language = {English},
  number = {5},
  journal = {Applied Cognitive Psychology},
  doi = {10.1002/acp.3456},
  author = {Davies, Graham M. and Granhag, Par-Anders},
  year = {SEP-OCT 2018},
  keywords = {include,announcement_RRs,note},
  pages = {525-525},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\WRYHE2NL\\Davies and Granhag - 2018 - ACP to publish Registered Reports.pdf},
  note = {WOS:000444224200001}
}

@article{dessing2015,
  title = {Human {{Movement Science}} Adopts {{Registered Reports}} for Hypothesis-Driven Research},
  volume = {44},
  issn = {0167-9457},
  language = {English},
  journal = {Human Movement Science},
  doi = {10.1016/j.humov.2015.09.011},
  author = {Dessing, Joost C. and Beek, Peter J.},
  month = dec,
  year = {2015},
  keywords = {include,announcement_RRs,note},
  pages = {A1-A2},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\VLADAHSN\\Dessing and Beek - 2015 - Human Movement Science adopts Registered Reports f.pdf},
  note = {WOS:000365361700001}
}

@article{donnellan2018,
  title = {Introduction to the Special Issue - {{A}} Replication Project in Personality Psychology},
  volume = {72},
  issn = {0092-6566},
  language = {English},
  journal = {Journal of Research in Personality},
  doi = {10.1016/j.jrp.2017.11.004},
  author = {Donnellan, M. Brent and Lucas, Richard E.},
  month = feb,
  year = {2018},
  keywords = {replicability,science,registered-reports,recommendations,special section,note,include_key_personal_XP},
  pages = {1-4},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\QSDHM5QU\\Donnellan and Lucas - 2018 - Introduction to the special issue - A replication .pdf},
  note = {WOS:000424724700001}
}

@article{eberlen2017,
  title = {Simulate This! {{An Introduction}} to {{Agent}}-{{Based Models}} and Their {{Power}} to {{Improve}} Your {{Research Practice}}},
  volume = {30},
  issn = {2397-8570},
  abstract = {The method of agent-based modeling is rarely used in social psychology, but has the potential to complement and improve traditional research practices. An agent-based model (ABM) consists of a number of virtual individuals the "agents" interacting in an artificial, experimenter-controlled environment. In this article, we discuss several characteristics of ABMs that could prove particularly useful with respect to recent recommendations aimed at countering issues related to the current "replication crisis". We address the potential synergies between planning and implementing an ABM on the one hand, and the endeavor of pre-registration on the other. We introduce ABMs as tools for both the generation and the improvement of theory, testing of hypotheses, and for extending traditional experimental approaches by facilitating the investigation of social processes from the intra-individual all the way up to the societal level. We describe examples of ABMs in social psychology, including a detailed description of the CollAct model of social learning. Finally, limitations and drawbacks of agent-based modeling are discussed. In annex 1 and 2, we provide literature and tool recommendations for getting started with an ABM.},
  language = {English},
  number = {1},
  journal = {International Review of Social Psychology},
  doi = {10.5334/irsp.115},
  author = {Eberlen, Julia and Scholz, Geeske and Gagliolo, Matteo},
  month = jul,
  year = {2017},
  keywords = {Methodology,replicability,registered reports,Replication Crisis,social-psychology,management,recommendations,Agent-Based Models,Computational Social Sciences,odd protocol,pre-registration,Social Psychology,us,include,note},
  pages = {149-160},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\JNAC7ZCA\\Eberlen et al. - 2017 - Simulate this! An Introduction to Agent-Based Mode.pdf},
  note = {WOS:000433442400002}
}

@article{elkins-brown2018,
  title = {The Misattribution of Emotions and the Error-Related Negativity: {{A}} Registered Report},
  volume = {109},
  issn = {0010-9452},
  abstract = {A growing body of work in social and affective neuroscience suggests that emotion plays an instrumental role in error monitoring processes, rather than only a moderating one. High-powered replications of studies that support this idea, however, are lacking. Here, we attempted a preregistered replication of our own study that had provided evidence for the functional role of emotions in error monitoring: that a neural signal of error monitoring-the error-related negativity-is reduced when participants undergo a misattribution of arousal procedure (Inzlicht \& Al-Khindi, 2012). Like a previous replication attempt (Rodilla et al, 2016), our misattribution procedure failed to reduce the amplitude of the ERN. However, it also failed its manipulation check to reduce state anxiety, limiting the conclusions we can draw. Nonetheless, these findings are consistent with the view that our original study may have been a false positive. We discuss these findings in the context of the replication crisis in psychology and of work on the emotional properties of the ERN. (C) 2018 Elsevier Ltd. All rights reserved.},
  language = {English},
  journal = {Cortex},
  doi = {10.1016/j.cortex.2018.08.017},
  author = {{Elkins-Brown}, Nathaniel and Saunders, Blair and Inzlicht, Michael},
  month = dec,
  year = {2018},
  keywords = {Replication,reliability,false discovery rate,motivation,Anxiety,anxiety,performance,punishment,Emotion,ern,anterior cingulate,brain activity,Misattribution,responsiveness,include,note},
  pages = {124-140},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\NNT8G2WC\\Elkins-Brown et al. - 2018 - The misattribution of emotions and the error-relat.pdf},
  note = {WOS:000452945800011}
}

@article{errington2014,
  title = {An Open Investigation of the Reproducibility of Cancer Biology Research},
  volume = {3},
  issn = {2050-084X},
  abstract = {It is widely believed that research that builds upon previously published findings has reproduced the original work. However, it is rare for researchers to perform or publish direct replications of existing results. The Reproducibility Project: Cancer Biology is an open investigation of reproducibility in preclinical cancer biology research. We have identified 50 high impact cancer biology articles published in the period 2010-2012, and plan to replicate a subset of experimental results from each article. A Registered Report detailing the proposed experimental designs and protocols for each subset of experiments will be peer reviewed and published prior to data collection. The results of these experiments will then be published in a Replication Study. The resulting open methodology and dataset will provide evidence about the reproducibility of high-impact results, and an opportunity to identify predictors of reproducibility.},
  language = {English},
  journal = {Elife},
  doi = {10.7554/elife.04333},
  author = {Errington, Timothy M. and Iorns, Elizabeth and Gunn, William and Tan, Fraser Elisabeth and Lomax, Joelle and Nosek, Brian A.},
  month = dec,
  year = {2014},
  keywords = {replication,science,neuroscience,publication,consequences,false,psychological-research,prevention,again,availability,include,note},
  pages = {e04333},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\6Y2G93BK\\Errington et al. - 2014 - An open investigation of the reproducibility of ca.pdf},
  note = {WOS:000346170600001}
}

@article{francis2018,
  title = {Registered Reports for {{Consciousness}} and {{Cognition}}},
  volume = {57},
  issn = {1053-8100},
  language = {English},
  journal = {Consciousness and Cognition},
  doi = {10.1016/j.concog.2017.10.007},
  author = {Francis, Gregory and Bachmann, Talis},
  month = jan,
  year = {2018},
  keywords = {include,announcement_RRs,note},
  pages = {A1-A3},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\6TPE5Y5S\\Francis and Bachmann - 2018 - Registered reports for Consciousness and Cognition.pdf},
  note = {WOS:000424856400001}
}

@article{frankenhuis2018,
  title = {Open {{Science Is Liberating}} and {{Can Foster Creativity}}},
  volume = {13},
  issn = {1745-6916},
  abstract = {Some scholars think that Open Science practices constrain researchers in ways that reduce their creativity, arguing, for instance, that preregistration discourages data exploration and so stifles discovery. In this article, we argue the opposite: Open Science practices are liberating and can foster creativity. Open Science practices are liberating because they (a) enable us to explore data transparently and comfortably; (b) reward quality, which is under our control, rather than outcomes, which are not; and (c) reduce the choke hold of needing to find "positive" results for career advancement. Open Science practices can foster creativity because they cultivate an open and flexible mind-set, create a more collaborative and constructive climate, and generate more accurate information and make it more accessible. In sum, Open Science liberates researchers more than it constrains them.},
  language = {English},
  number = {4},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691618767878},
  author = {Frankenhuis, Willem E. and Nettle, Daniel},
  month = jul,
  year = {2018},
  keywords = {replication,reproducibility,open science,preregistration,replicability,creativity,doubt,uncertainty,competition,registered-reports,information,knowledge,psychological science,scientific utopia,standard,include,note},
  pages = {439-447},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\K5JRQZJ7\\Frankenhuis and Nettle - 2018 - Open Science Is Liberating and Can Foster Creativi.pdf},
  note = {WOS:000438605100005}
}

@article{geukes2016,
  title = {{Ways Out of the Crisis of Confidence: Individual Steps Toward a Reliable and Open Science}},
  volume = {23},
  issn = {1612-5010},
  abstract = {Psychology faces a so-called crisis of confidence as does sport psychology (see title of this special issue). While the debate on its causes and consequences is lively, the deduction of individual opportunities to collectively increase trust is missing. We propose ways out of this crisis and above all describe individual steps toward a reliable and open science. Reliable science refers to the publication of robust effects, as well as to direct and conceptual replications, and open science refers to transparency regarding the design (preregistration), the conducting (open material), and the analysis (open data, reproducible code) of scientific studies. The commitment to reliable and open science wilt change our behavior in the diverse roles within the scientific system (e.g., as researchers, reviewers, supervisors, editors, or members of commissions). In this sense, we consider the current discussion as a chance to enhance the trustworthiness of our findings and to ultimately create justified confidence.},
  language = {German},
  number = {3},
  journal = {Zeitschrift Fur Sportpsychologie},
  doi = {2018080903521000726},
  author = {Geukes, Katharina and Schoenbrodt, Felix D. and Utesch, Till and Geukes, Sebastian and Back, Mitja D.},
  year = {2016},
  keywords = {replication,open science,preregistration,replicability,incentives,research practices,registered-reports,truth,recommendations,special section,psychological-research,crisis of confidence,exercise,sport,include,note},
  pages = {99-109},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7U4AQTF3\\Geukes et al. - 2016 - Ways Out of the Crisis of Confidence Individual S.pdf},
  note = {WOS:000392884700005}
}

@article{goldstein2019,
  title = {To {{FinTech}} and {{Beyond}}},
  volume = {32},
  issn = {0893-9454},
  abstract = {FinTech is about the introduction of new technologies into the financial sector, and it is now revolutionizing the financial industry. In 2017, when the academic finance community was not actively researching FinTech, the editorial team of the Review of Financial Studies launched a competition to develop research proposals focused on this topic. This special issue is the result. In this introductory article, we describe the recent FinTech phenomenon and the novel editorial protocol employed for this special issue following the Registered Reports format. We discuss what we learned from the submitted proposals about the field of FinTech and which ones we selected to be completed and ultimately come out in this special issue. We also provide several observations to help guide future research in the emerging area of FinTech.},
  language = {English},
  number = {5},
  journal = {Review of Financial Studies},
  doi = {10.1093/rfs/hhz025},
  author = {Goldstein, Itay and Jiang, Wei and Karolyi, G. Andrew},
  month = may,
  year = {2019},
  keywords = {include,empirical_case_study},
  pages = {1647-1661},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\LH8KDQ9S\\Goldstein et al. - 2019 - To FinTech and Beyond.pdf},
  note = {WOS:000467528700001}
}

@article{gorman2017,
  title = {The Decline Effect in Evaluations of the Impact of the {{Strengthening Families Program}} for {{Youth}} 10-14 ({{SFP}} 10-14) on Adolescent Substance Use},
  volume = {81},
  issn = {0190-7409},
  abstract = {The decline effect refers to the situation whereby an initially positive set of research findings concerning a phenomenon fail to be replicated in subsequent studies. One explanation for the occurrence of the decline effect is that the initial positive results reported in publications from a single research team are the product of the use of flexible data analysis practices and selective reporting. The present paper reviews evaluations of the Strengthening Families Program for Youth 10-14 (SFP 10-14) conducted by the research group who developed the program and five independent replication studies. The focus is on the effects reported for adolescent substance use. It is argued that the isolated statistically significant results reported in the original studies were produced through the use of flexible data analysis practices such as changing outcome variables across publications and post hoc alterations in study design. In light of this, it is unsurprising that the five independent evaluations have failed to replicate these results. A strength of three of the independent evaluations is that they were registered in a clinical trials registry and had published their study protocols. Both of these procedures limit the opportunity to conduct flexible data analysis. It is recommended that future evaluations of the SFP 10-14 should employ these procedures as well as utilizing the registered reports publication process, making their data and methods openly available to other researchers, and including a skeptic in their research team.},
  language = {English},
  journal = {Children and Youth Services Review},
  doi = {10.1016/j.childyouth.2017.07.009},
  author = {Gorman, Dennis M.},
  month = oct,
  year = {2017},
  keywords = {Replication,cultural-adaptation,Decline effect,Family-based prevention,Flexible data   analysis,implementation quality,initiation outcomes,misuse,past base-line,prosper,protective shield,randomized   controlled-trial,Selective reporting,Substance use,universal preventive intervention,use outcomes,include,note},
  pages = {29-39},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\GF8TM4R8\\Gorman - 2017 - The decline effect in evaluations of the impact of.pdf},
  note = {WOS:000412616400005}
}

@article{gorman2019,
  title = {Use of Publication Procedures to Improve Research Integrity by Addiction Journals},
  volume = {114},
  issn = {0965-2140},
  abstract = {Background and Aims The credibility crisis evident in many academic disciplines has led peer-reviewed journals to implement procedures to reduce use of flexible data analysis practices and selective reporting of results. This exploratory study examined the adoption of six of these procedures by addiction journals. Methods Thirty-eight high-impact addiction journals were identified using the 2018 Clarivate Analytics Journal Citation Report for 2017 ranks. The online instructions for authors were reviewed for references to six publication procedures: conflict of interest disclosure, reporting guidelines, clinical trial registration, registration of other study designs, data-sharing and registered reports. The webpages of the Center for Open Science and Consolidated Standards of Reporting Trials (CONSORT) were also reviewed for data pertaining to registered reports and reporting guidelines, respectively. Results The range of procedures adopted by the addiction journals was 0-5, with a mean of 2.66. Conflict-of-interest disclosure was required by all but one journal. Encouraging data-sharing was the next most commonly required procedure. Fewer than half the journals recommended specific reporting guidelines or required registration of clinical trials, and only four required procedures to pre-specify hypotheses and analytical methods. Conclusions While many addiction journals have adopted publication procedures to improve research integrity, these can be limited by their voluntary nature and monitoring difficulties. More stringent requirements that lock researchers into specific hypotheses and analyses have not been widely adopted.},
  language = {English},
  number = {8},
  journal = {Addiction},
  doi = {10.1111/add.14604},
  author = {Gorman, Dennis M.},
  month = aug,
  year = {2019},
  keywords = {empirical,include,RRs,note},
  pages = {1478-1486},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\UMH8IRBI\\Gorman - 2019 - Use of publication procedures to improve research .pdf},
  note = {WOS:000475479000021}
}

@article{gorman2019a,
  title = {A {{Systems Approach}} to {{Understanding}} and {{Improving Research Integrity}}},
  volume = {25},
  issn = {1353-3452},
  abstract = {Concern about the integrity of empirical research has arisen in recent years in the light of studies showing the vast majority of publications in academic journals report positive results, many of these results are false and cannot be replicated, and many positive results are the product of data dredging and the application of flexible data analysis practices coupled with selective reporting. While a number of potential solutions have been proposed, the effects of these are poorly understood and empirical evaluation of each would take many years. We propose that methods from the systems sciences be used to assess the effects, both positive and negative, of proposed solutions to the problem of declining research integrity such as study registration, Registered Reports, and open access to methods and data. In order to illustrate the potential application of systems science methods to the study of research integrity, we describe three broad types of models: one built on the characteristics of specific academic disciplines; one a diffusion of research norms model conceptualizing researchers as susceptible, infected and recovered; and one conceptualizing publications as a product produced by an industry comprised of academics who respond to incentives and disincentives.},
  language = {English},
  number = {1},
  journal = {Science and Engineering Ethics},
  doi = {10.1007/s11948-017-9986-z},
  author = {Gorman, Dennis M. and Elkins, Amber D. and Lawley, Mark},
  month = feb,
  year = {2019},
  keywords = {include,blind_analysis,RRs,system_dynamics_models,non-empirical_opinion,note},
  pages = {211-229},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\KLJM29V8\\Gorman et al. - 2019 - A Systems Approach to Understanding and Improving .pdf},
  note = {WOS:000461310400012}
}

@article{grand2018,
  title = {From {{Outcome}} to {{Process Focus}}: {{Fostering}} a {{More Robust Psychological Science Through Registered Reports}} and {{Results}}-{{Blind Reviewing}}},
  volume = {13},
  issn = {1745-6916},
  abstract = {A variety of alternative mechanisms, strategies, and "ways of doing" have been proposed for improving the rigor and robustness of published research in the psychological sciences in recent years. In this article, we describe two existing but underused publication modelsregistered reporting (RR) and results-blind reviewing (RBR)-that we believe would contribute in important ways to improving both the conduct and evaluation of psychological research. We first outline the procedures and distinguishing features of both publication pathways and note their value for promoting positive changes to current scientific practices. We posit that a significant value of RR and RBR is their potential to promote a greater focus on the research process (i.e., how and why research is conducted) relative to research outcomes (i.e., what was observed or concluded from research). We conclude by discussing what we perceive to be five common beliefs about RR and RBR practices and attempt to provide a balanced perspective of the realities likely to be experienced with these systems.},
  language = {English},
  number = {4},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691618767883},
  author = {Grand, James A. and Rogelberg, Steven G. and Banks, George C. and Landis, Ronald S. and Tonidandel, Scott},
  month = jul,
  year = {2018},
  keywords = {include_key},
  pages = {448-456},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\D4XZ22MN\\Grand et al. - 2018 - From Outcome to Process Focus Fostering a More Ro.pdf},
  note = {WOS:000438605100006}
}

@article{greiff2018,
  title = {{{EJPA Introduces Registered Reports}} as {{New Submission Format}}},
  volume = {34},
  issn = {1015-5759},
  language = {English},
  number = {4},
  journal = {European Journal of Psychological Assessment},
  doi = {10.1027/1015-5759/a000492},
  author = {Greiff, Samuel and Allen, Mark S.},
  month = jul,
  year = {2018},
  keywords = {include_key},
  pages = {217-219},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\U85CU3QE\\Greiff and Allen - 2018 - EJPA Introduces Registered Reports as New Submissi.pdf},
  note = {WOS:000443318600001}
}

@article{grubb2019,
  title = {Investigating the Role of Exogenous Cueing on Selection History Formation},
  volume = {26},
  issn = {1069-9384},
  abstract = {An abundance of recent empirical data suggest that repeatedly allocating visual attention to task-relevant and/or reward-predicting features in the visual world engenders an attentional bias for these frequently attended stimuli, even when they become task irrelevant and no longer predict reward. In short, attentional selection in the past hinders voluntary control of attention in the present. But do such enduring attentional biases rely on a history of voluntary, goal-directed attentional selection, or can they be generated through involuntary, effortless attentional allocation? An abrupt visual onset triggers such a reflexive allocation of covert spatial attention to its location in the visual field, automatically modulating numerous aspects of visual perception. In this Registered Report, we asked whether a selection history that has been reflexively and involuntarily derived (i.e., through abrupt-onset cueing) also interferes with goal-directed attentional control, even in the complete absence of exogenous cues. To build spatially distinct histories of exogenous selection, we presented abrupt-onset cues twice as often at one of two task locations, and as expected, these cues reflexively modulated visual processing: task accuracy increased, and response times (RTs) decreased, when the cue appeared near the target's location, relative to that of the distractor. Upon removal of these cues, however, we found no evidence that exogenous selection history modulated task performance: task accuracy and RTs at the previously most-cued and previously least-cued sides were statistically indistinguishable. Thus, unlike voluntarily directed attention, involuntary attentional allocation may not be sufficient to engender historically contingent selection biases.},
  language = {English},
  number = {4},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/s13423-019-01591-z},
  author = {Grubb, Michael A. and Christensen, Gabriela and Albanese, John},
  month = aug,
  year = {2019},
  keywords = {performance,attention affects,contrast,Exogenous attention,reflexive,Selection history,Spatial attention,visual-attention,voluntary,include,note},
  pages = {1282-1288},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\XD8YUQM9\\Grubb et al. - 2019 - Investigating the role of exogenous cueing on sele.pdf},
  note = {WOS:000482783800013}
}

@article{halperin2018,
  title = {Strengthening the {{Practice}} of {{Exercise}} and {{Sport}}-{{Science Research}}},
  volume = {13},
  issn = {1555-0265},
  abstract = {Exercise and sport sciences continue to grow as a collective set of disciplines investigating a broad array of basic and applied research questions. Despite the progress, there is room for improvement. A number of problems pertaining to reliability and validity of research practices hinder advancement and the potential impact of the field. These problems include inadequate validation of surrogate outcomes, too few longitudinal and replication studies, limited reporting of null or trivial results, and insufficient scientific transparency. The purpose of this review is to discuss these problems as they pertain to exercise and sport sciences based on their treatment in other disciplines, namely psychology and medicine, and to propose a number of solutions and recommendations.},
  language = {English},
  number = {2},
  journal = {International Journal of Sports Physiology and Performance},
  doi = {10.1123/ijspp.2017-0322},
  author = {Halperin, Israel and Vigotsky, Andrew D. and Foster, Carl and Pyne, David B.},
  month = feb,
  year = {2018},
  keywords = {replication,methodology,psychology,replicability,registered-reports,crisis,programs,biomarkers,hypothesis,muscle protein-synthesis,null results,surrogate end-points,include,note},
  pages = {127-134},
  note = {WOS:000429367100002}
}

@article{hardwicke2018,
  title = {Mapping the Universe of Registered Reports},
  volume = {2},
  issn = {2397-3374},
  language = {English},
  number = {11},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-018-0444-y},
  author = {Hardwicke, Tom E. and Ioannidis, John P. A.},
  month = nov,
  year = {2018},
  keywords = {empirical,trials,include_key},
  pages = {793-796},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\KZYIXHEE\\Hardwicke and Ioannidis - 2018 - Mapping the universe of registered reports.pdf},
  note = {WOS:000449539900003}
}

@article{horbach2019,
  title = {The Ability of Different Peer Review Procedures to Flag Problematic Publications},
  volume = {118},
  issn = {0138-9130},
  abstract = {There is a mounting worry about erroneous and outright fraudulent research that gets published in the scientific literature. Although peer review's ability to filter out such publications is contentious, several peer review innovations attempt to do just that. However, there is very little systematic evidence documenting the ability of different review procedures to flag problematic publications. In this article, we use survey data on peer review in a wide range of journals to compare the retraction rates of specific review procedures, using the Retraction Watch database. We were able to identify which peer review procedures were used since 2000 for 361 journals, publishing a total of 833,172 articles, of which 670 were retracted. After addressing the dual character of retractions, signalling both a failure to identify problems prior to publication, but also the willingness to correct mistakes, we empirically assess review procedures. With considerable conceptual caveats, we were able to identify peer review procedures that seem able to detect problematic research better than others. Results were verified for disciplinary differences and variation between reasons for retraction. This leads to informed recommendations for journal editors about strengths and weaknesses of specific peer review procedures, allowing them to select review procedures that address issues most relevant to their field.},
  language = {English},
  number = {1},
  journal = {Scientometrics},
  doi = {10.1007/s11192-018-2969-2},
  author = {Horbach, S. P. J. M. and Halffman, W.},
  month = jan,
  year = {2019},
  keywords = {empirical,retraction,include,RRs},
  pages = {339-373},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\H3QYSRSK\\Horbach and Halffman - 2019 - The ability of different peer review procedures to.pdf},
  note = {WOS:000456290600016}
}

@article{islam2018,
  title = {Research {{Partnerships Between Academics}} and {{Consulting Firms}}: {{A Stakeholder Analysis}}},
  volume = {11},
  issn = {1754-9426},
  abstract = {The focal article (LaPierre et al., 2018) proposes several steps in developing a research partnership with organizations. We commend LaPierre and colleagues for bringing to light these recommendations. We agree that research partnerships may prove valuable for the science of industrial and organizational (I-O) psychology. For I-O psychology to grow as a science, more appropriate sampling and more relevant data sources are necessary (Landers \& Behrend, 2015). Although I-O psychology master's and PhD programs continue to grow and produce more I-O psychology graduates that enter the applied marketplace, there remains a paucity of applied research partnerships between academics and organizations. Research partnerships are often established in other disciplines (i.e., computer science, public health, biochemistry) and have resulted in fruitful relationships for both parties (D'Este \& Iammarino, 2010; Israel, Schulz, Parker, \& Becker, 1998; Santoro \& Betts, 2002), but similar partnerships have not become the norm in I-O psychology. Despite a growing number of I-O psychology graduates and programs (Shellenbarger, 2010), I-O psychology academics have not leveraged those relationships to create research partnerships between universities and business. We would argue that this lack of research partnerships is due to the difficulty of navigating and negotiating with the multiple stakeholders involved in the process of developing a research partnership.},
  language = {English},
  number = {4},
  journal = {Industrial and Organizational Psychology-Perspectives on Science and Practice},
  doi = {10.1017/iop.2018.121},
  author = {Islam, Sayeedul and Lahti, Ken and Chetta, Michael H.},
  month = dec,
  year = {2018},
  keywords = {registered-reports,satisfaction,include,note},
  pages = {596-605},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\BU5WUGLP\\Islam et al. - 2018 - Research Partnerships Between Academics and Consul.pdf},
  note = {WOS:000454499700006}
}

@article{jamieson2019,
  title = {Registered {{Reports}}},
  volume = {73},
  issn = {1196-1961},
  language = {English},
  number = {1},
  journal = {Canadian Journal of Experimental Psychology-Revue Canadienne De Psychologie Experimentale},
  doi = {10.1037/cep0000169},
  author = {Jamieson, Randall K. and Bodner, Glen E. and {Saint-Aubin}, Jean and Titone, Debra},
  month = mar,
  year = {2019},
  keywords = {include,announcement_RRs,note},
  pages = {3-4},
  note = {WOS:000461486700002}
}

@article{kal2018,
  title = {Does Implicit Motor Learning Lead to Greater Automatization of Motor Skills Compared to Explicit Motor Learning? {{A}} Systematic Review},
  volume = {13},
  issn = {1932-6203},
  abstract = {Background Implicit motor learning is considered to be particularly effective for learning sports-related motor skills. It should foster movement automaticity and thereby facilitate performance in multitasking and high-pressure environments. To scrutinize this hypothesis, we systematically reviewed all studies that compared the degree of automatization achieved (as indicated by dual-task performance) after implicit compared to explicit interventions for sports-related motor tasks. Methods For this systematic review (CRD42016038249) conventional (MEDLINE, CENTRAL, Embase, PsycINFO, SportDiscus, Web of Science) and grey literature were searched. Two reviewers independently screened reports, extracted data, and performed risk of bias assessment. Implicit interventions of interest were analogy-, errorless-, dual-task-, and external focus learning. Data analysis involved descriptive synthesis of group comparisons on absolute motor dual-task (DT) performance, and motor DT performance relative to single-task motor performance (motor DTCs). Results Of the 4125 reports identified, we included 25 controlled trials that described 39 implicit-explicit group comparisons. Risk of bias was unclear across trials. Most comparisons did not show group differences. Some comparisons showed superior absolute motor DT performance (N = 2), superior motor DTCs (N = 4), or both (N = 3) for the implicit compared to the explicit group. The explicit group showed superior absolute motor DT performance in two comparisons. Conclusions Most comparisons did not show group differences in automaticity. The remaining comparisons leaned more toward a greater degree of movement automaticity after implicit learning than explicit learning. However, due to an overall unclear risk of bias the strength of the evidence is level 3. Motor learning-specific guidelines for design and especially reporting are warranted to further strengthen the evidence and facilitate low-risk-of-bias trials.},
  language = {English},
  number = {9},
  journal = {Plos One},
  doi = {10.1371/journal.pone.0203591},
  author = {Kal, Elmar and Prosee, Rens and Winters, Marinus and {van der Kamp}, John},
  month = sep,
  year = {2018},
  keywords = {registered-reports,metaanalysis,acquisition,analogy,attentional focus,automaticity,errorless,know-how,memory   processes,task-performance,include,note},
  pages = {e0203591},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\B5HNIIRG\\Kal et al. - 2018 - Does implicit motor learning lead to greater autom.pdf},
  note = {WOS:000443789900077}
}

@article{kettler2019,
  title = {Conducting {{Registered Report Research}}: {{A Conversation With Matthew McBee}} and {{Scott Peters}}},
  volume = {30},
  issn = {1932-202X},
  abstract = {The movement toward open-science is multifaceted with the general goal to promote both better scientific practices and greater access to scientific information. One aspect of the open-science framework is the recommended use of registered reports replacing the legacy model that dictates research manuscripts are submitted for initial review only after the completion of the study and the development of a full manuscript. At the time of this conversation, 125 journals were participating in the initiative to accept registered reports. At the completion of the conversation, that number had increased to 130. The majority of those journals are in the fields of psychology and medicine. Gifted Child Quarterly and the Journal of Advanced Academics were among the first education journals to open their editorial policies to accept and encourage registered report research. Matthew McBee and Scott Peters have consistently advocated for this movement toward registered reports and open science in gifted education and advanced academic research. This interview shares their rationale for the movement toward registered reports and the potential benefits to research in the fields of gifted education and advanced academics.},
  language = {English},
  number = {1},
  journal = {Journal of Advanced Academics},
  doi = {10.1177/1932202x18809371},
  author = {Kettler, Todd},
  month = feb,
  year = {2019},
  keywords = {include_key,empirical_case_study},
  pages = {3-26},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\224UVYQM\\Kettler - 2019 - Conducting Registered Report Research A Conversat.pdf},
  note = {WOS:000455397400001}
}

@article{kiyonaga2019,
  title = {Practical {{Considerations}} for {{Navigating Registered Reports}}},
  volume = {42},
  issn = {0166-2236},
  abstract = {Recent open science efforts to improve rigor and reliability have sparked great enthusiasm. Among these, the Registered Report publication format integrates best practices in hypothesis-driven research with peer review that occurs before the research is conducted. Here, we detail practical recommendations to help researchers negotiate the mechanics of this developing format.},
  language = {English},
  number = {9},
  journal = {Trends in Neurosciences},
  doi = {10.1016/j.tins.2019.07.003},
  author = {Kiyonaga, Anastasia and Scimeca, Jason M.},
  month = sep,
  year = {2019},
  keywords = {include_key_has_critique,guidelines_RRs},
  pages = {568-572},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\PZLR8U9Y\\Kiyonaga and Scimeca - 2019 - Practical Considerations for Navigating Registered.pdf},
  note = {WOS:000483367900004}
}

@article{larson2017,
  title = {Sample Size Calculations in Human Electrophysiology ({{EEG}} and {{ERP}}) Studies: {{A}} Systematic Review and Recommendations for Increased Rigor},
  volume = {111},
  issn = {0167-8760},
  abstract = {There is increasing focus across scientific fields on adequate sample sizes to ensure non-biased and reproducible effects. Very few studies, however, report sample size calculations or even the information needed to accurately calculate sample sizes for grants and future research. We systematically reviewed 100 randomly selected clinical human electrophysiology studies from six high impact journals that frequently publish electroencephalography (EEG) and event-related potential (ERP) research to determine the proportion of studies that reported sample size calculations, as well as the proportion of studies reporting the necessary components to complete such calculations. Studies were coded by the two authors blinded to the other's results. Inter-rater reliability was 100\% for the sample size calculations and kappa above 0.82 for all other variables. Zero of the 100 studies (0\%) reported sample size calculations. 77\% utilized repeated-measures designs, yet zero studies (0\%) reported the necessary variances and correlations among repeated measures to accurately calculate future sample sizes. Most studies (93\%) reported study statistical values (e.g., For t values). Only 40\% reported effect sizes, 56\% reported mean values, and 47\% reported indices of variance (e.g., standard deviations/standard errors). Absence of such information hinders accurate determination of sample sizes for study design, grant applications, and meta-analyses of research and whether studies were adequately powered to detect effects of interest. Increased focus on sample size calculations, utilization of registered reports, and presenting information detailing sample size calculations and statistics for future researchers are needed and will increase sample size-related scientific rigor in human electrophysiology research. (C) 2016 Elsevier B.V. All rights reserved.},
  language = {English},
  journal = {International Journal of Psychophysiology},
  doi = {10.1016/j.ijpsycho.2016.06.015},
  author = {Larson, Michael J. and Carbine, Kaylie A.},
  month = jan,
  year = {2017},
  keywords = {recommendations,include,empirical_SR,note,power_calculation_prev},
  pages = {33-41},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\AGU5CYWT\\Larson and Carbine - 2017 - Sample size calculations in human electrophysiolog.pdf},
  note = {WOS:000392554600004}
}

@article{lee2018,
  title = {Reproducible and Replicable Pain Research: A Critical Review},
  volume = {159},
  issn = {0304-3959},
  language = {English},
  number = {9},
  journal = {Pain},
  doi = {10.1097/j.pain.0000000000001254},
  author = {Lee, Hopin and Lamb, Sarah E. and Bagg, Matthew K. and Toomey, Elaine and Cashin, Aidan G. and Moseley, G. Lorimer},
  month = sep,
  year = {2018},
  keywords = {empirical,sample-size,include,editorial_policies,note},
  pages = {1683-1689},
  note = {WOS:000451225300005}
}

@article{li2018,
  title = {Effects of an {{Information Sharing System}} on {{Employee Creativity}}, {{Engagement}}, and {{Performance}}},
  volume = {56},
  issn = {0021-8456},
  abstract = {Many service organizations rely on information sharing systems to boost employee creativity to meet customer needs. We conducted a field experiment in a retail chain, based on a registered report accepted by JAR, to test whether an information sharing system recording employees' creative work affected the quality of creative work, job engagement, and financial performance. We found that, on average, this system did not have a significant effect on any of these outcomes. However, it significantly improved the quality of creative work in stores that had accessed the system more frequently and in stores with fewer same-company nearby stores. It also improved creative work and job engagement in stores in divergent markets, where customers needed more customization. We found weak evidence of better financial results where salespeople had lower creative talent before the system was introduced. Our findings shed light on those conditions in which information sharing systems affect employees' creative work.},
  language = {English},
  number = {2},
  journal = {Journal of Accounting Research},
  doi = {10.1111/1475-679x.12202},
  author = {Li, Shelley Xin and Sandino, Tatiana},
  month = may,
  year = {2018},
  keywords = {design,creativity,productivity,field experiments,impact,selection,authority,engagement,generation,geographically dispersed   organizations,idea,information sharing systems,integration,knowledge sharing,labor management,learning,organizations,retail chains,include,note},
  pages = {713-747},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\PL4WFUUB\\Li and Sandino - 2018 - Effects of an Information Sharing System on Employ.pdf},
  note = {WOS:000430467200009}
}

@article{marsden2018,
  title = {Replication in {{Second Language Research}}: {{Narrative}} and {{Systematic Reviews}} and {{Recommendations}} for the {{Field}}},
  volume = {68},
  issn = {0023-8333},
  abstract = {Despite its critical role for the development of the field, little is known about replication in second language (L2) research. To better understand replication practice, we first provide a narrative review of challenges related to replication, drawing on recent developments in psychology. This discussion frames and motivates a systematic review, building on syntheses of replication in psychology, education, and L2 research. We coded 67 self-labeled L2 replication studies found across 26 journals for 136 characteristics. We estimated a mean rate of 1 published replication study for every 400 articles, with a mean of 6.64 years between initial and replication studies and a mean of 117 citations of the initial study before a replication was published. Replication studies had an annual mean of 7.3 citations, much higher than averages in linguistics and education. Overlap in authorship between initial and replication studies and the availability of the initial materials both increased the likelihood of a replication supporting the initial findings. Our sample contained no direct (exact) replication attempts, and changes made to initial studies were numerous and wide ranging, which likely obscured, if not undermined, the interpretability of replication studies. To improve the amount and quality of L2 replication research, we propose 16 recommendations relating to rationale, nomenclature, design, infrastructure, and incentivization for collaboration and publication.},
  language = {English},
  number = {2},
  journal = {Language Learning},
  doi = {10.1111/lang.12286},
  author = {Marsden, Emma and {Morgan-Short}, Kara and Thompson, Sophie and Abugaber, David},
  month = jun,
  year = {2018},
  keywords = {replication,publishing,methodology,registered reports,research design,systematic review,crisis,attention,comprehension,counterfactuals,grammar,implicit,language-acquisition,processing instruction,quantitative research,second language,include,note},
  pages = {321-391},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\A55Z9TXC\\Marsden et al. - 2018 - Replication in Second Language Research Narrative.pdf},
  note = {WOS:000434147700002}
}

@article{marsden2018a,
  title = {Introducing {{Registered Reports}} at {{Language Learning}}: {{Promoting Transparency}}, {{Replication}}, and a {{Synthetic Ethic}} in the {{Language Sciences}}},
  volume = {68},
  issn = {0023-8333},
  abstract = {The past few years have seen growing interest in open science practices, which include initiatives to increase transparency in research methods, data collection, and analysis; enhance accessibility to data and materials; and improve the dissemination of findings to broader audiences. Language Learning is enhancing its participation in the open science movement by launching Registered Reports as an article category as of January 1, 2018. Registered Reports allow authors to submit the conceptual justifications and the full method and analysis protocol of their study to peer review prior to data collection. High-quality submissions then receive provisional, in-principle acceptance. Provided that data collection, analyses, and reporting follow the proposed and accepted methodology and analysis protocols, the article is subsequently publishable whatever the findings. We outline key concerns leading to the development of Registered Reports, describe its core features, and discuss some of its benefits and weaknesses.},
  language = {English},
  number = {2},
  journal = {Language Learning},
  doi = {10.1111/lang.12284},
  author = {Marsden, Emma and {Morgan-Short}, Kara and Trofimovich, Pavel and Ellis, Nick C.},
  month = jun,
  year = {2018},
  keywords = {replication,transparency,open science,publication bias,preregistration,peer review,registered report,funder_rr_partnerships,include_key_has_critique},
  pages = {309-320},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7QXSW8BW\\Marsden et al. - 2018 - Introducing Registered Reports at Language Learnin.pdf},
  note = {WOS:000434147700001}
}

@article{mcbee2018,
  title = {A {{Call}} for {{Open Science}} in {{Giftedness Research}}},
  volume = {62},
  issn = {0016-9862},
  abstract = {Current practices in study design and data analysis have led to low reproducibility and replicability of findings in fields such as psychology, medicine, biology, and economics. Because gifted education research relies on the same underlying statistical and sociological paradigms, it is likely that it too suffers from these problems. This article discusses the origin of the poor replicability and introduces a set of open science practices that can increase the rigor and trustworthiness of gifted education's scientific findings: preregistration, open data and open materials, registered reports, and preprints. Readers are directed to Internet resources for facilitating open science. To model these practices, a pre peer-review preprint of this article is available at https://psyarxiv.com/nhuv3/.},
  language = {English},
  number = {4},
  journal = {Gifted Child Quarterly},
  doi = {10.1177/0016986218784178},
  author = {McBee, Matthew T. and Makel, Matthew C. and Peters, Scott J. and Matthews, Michael S.},
  month = oct,
  year = {2018},
  keywords = {replication,reproducibility,replication crisis,publication bias,preregistration,p-hacking,HARKing,open materials,registered reports,open data,citations,registered report,questionable research practices (QRPs),file   drawer,open   science,psychological-science,include,note},
  pages = {374-388},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\EUHETPXE\\McBee et al. - 2018 - A Call for Open Science in Giftedness Research.pdf},
  note = {WOS:000444404500003}
}

@article{mcewan2018,
  title = {On {{Replication}} in {{Communication Science}}},
  volume = {69},
  issn = {1051-0974},
  abstract = {Replications are an important part of the research process because they allow for greater confidence in the findings of communication research. However, engaging in replications is often undervalued, replication studies can be difficult to publish, and thus it is difficult for individual scholars to devote their resources toward replication. This essay outlines the importance of replications for communication science and provides a framework for this special issue on replications. The authors also issue a call for communication scholars to consider future projects and structural changes that would incentivize future replication studies.},
  language = {English},
  number = {3},
  journal = {Communication Studies},
  doi = {10.1080/10510974.2018.1464938},
  author = {McEwan, Bree and Carpenter, Christopher J. and Westerman, David},
  year = {2018},
  keywords = {design,Quantitative Methods,Communication Research,Communication Science,Meta-Analysis,Registered   Reports,Replications,include,note},
  pages = {235-241},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7UYAJ2XC\\McEwan et al. - 2018 - On Replication in Communication Science.pdf},
  note = {WOS:000436192200001}
}

@article{mcintosh2017,
  title = {Exploratory Reports: {{A}} New Article Type for {{Cortex}}},
  volume = {96},
  issn = {0010-9452},
  language = {English},
  journal = {Cortex},
  doi = {10.1016/j.cortex.2017.07.014},
  author = {McIntosh, Robert D.},
  month = nov,
  year = {2017},
  keywords = {incentives,registered-reports,include_key},
  pages = {A1-A4},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\PM6P7UJ3\\McIntosh - 2017 - Exploratory reports A new article type for Cortex.pdf},
  note = {WOS:000415912600001}
}

@article{mehlenbacher2019,
  title = {Registered {{Reports}}: {{Genre Evolution}} and the {{Research Article}}},
  volume = {36},
  issn = {0741-0883},
  abstract = {The research article is a staple genre in the economy of scientific research, and although research articles have received considerable treatment in genre scholarship, little attention has been given to the important development of Registered Reports. Registered Reports are an emerging, hybrid genre that proceeds through a two-stage model of peer review. This article charts the emergence of Registered Reports and explores how this new form intervenes in the evolution of the research article genre by replacing the central topoi of novelty with methodological rigor. Specifically, I investigate this discursive and publishing phenomenon by describing current conversations about challenges in replicating research studies, the rhetorical exigence those conversations create, and how Registered Reports respond to this exigence. Then, to better understand this emerging form, I present an empirical study of the genre itself by closely examining four articles published under the Registered Report model from the journal Royal Society Open Science and then investigating the genre hybridity by examining 32 protocols (Stage 1 Registered Reports) and 77 completed (Stage 2 Registered Reports) from a range of journals in the life and psychological sciences. Findings from this study suggest Registered Reports mark a notable intervention in the research article genre for life and psychological sciences, centering the reporting of science in serious methodological debates.},
  language = {English},
  number = {1},
  journal = {Written Communication},
  doi = {10.1177/0741088318804534},
  author = {Mehlenbacher, Ashley Rose},
  month = jan,
  year = {2019},
  keywords = {empirical,include_key},
  pages = {38-67},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\I242KRHE\\Mehlenbacher - 2019 - Registered Reports Genre Evolution and the Resear.pdf},
  note = {WOS:000453569000003}
}

@article{munafo2017,
  title = {Improving the {{Efficiency}} of {{Grant}} and {{Journal Peer Review}}: {{Registered Reports Funding}}},
  volume = {19},
  issn = {1462-2203},
  language = {English},
  number = {7},
  journal = {Nicotine \& Tobacco Research},
  doi = {10.1093/ntr/ntx081},
  author = {Munafo, Marcus R.},
  month = jul,
  year = {2017},
  keywords = {nicotine,tobacco research,include,note,funder_rr_partnerships,announcement_funder_rr_partnership},
  pages = {773-773},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\DNYC7NG5\\Munafo - 2017 - Improving the Efficiency of Grant and Journal Peer.pdf},
  note = {WOS:000404930300001}
}

@article{munafo2017a,
  title = {A Manifesto for Reproducible Science},
  volume = {1},
  issn = {2397-3374},
  abstract = {Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
  language = {English},
  number = {1},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-016-0021},
  author = {Munafo, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and {du Sert}, Nathalie Percie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
  month = jan,
  year = {2017},
  keywords = {include,note,funder_rr_partnerships},
  pages = {UNSP 0021},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\VI8TJSD4\\Munafo et al. - 2017 - A manifesto for reproducible science.pdf},
  note = {WOS:000418775900021}
}

@article{munafo2014,
  title = {Registered {{Reports}}: {{A}} New Submission Format at {{Drug}} and {{Alcohol Dependence}}},
  volume = {137},
  issn = {0376-8716},
  language = {English},
  journal = {Drug and Alcohol Dependence},
  doi = {10.1016/j.drugalcdep.2014.02.699},
  author = {Munafo, Marcus R. and Strain, Eric},
  month = apr,
  year = {2014},
  keywords = {include,announcement_RRs,note},
  pages = {1-2},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\M9VV8Z65\\Munafo and Strain - 2014 - Registered Reports A new submission format at Dru.pdf},
  note = {WOS:000334134200001}
}

@article{nosek2018,
  title = {The Preregistration Revolution},
  volume = {115},
  issn = {0027-8424},
  abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes-a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
  language = {English},
  number = {11},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  doi = {10.1073/pnas.1708274114},
  author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
  month = mar,
  year = {2018},
  keywords = {transparency,open science,methodology,confirmatory analysis,exploratory analysis,preregistration,bias,psychology,science,registration,file drawer,registered reports,inference,truth,false,include,note},
  pages = {2600-2606},
  note = {WOS:000427245400039}
}

@article{nosek2017,
  title = {Reproducibility in {{Cancer Biology}}: {{Making}} Sense of Replications},
  volume = {6},
  issn = {2050-084X},
  abstract = {The first results from the Reproducibility Project: Cancer Biology suggest that there is scope for improving reproducibility in pre-clinical cancer research.},
  language = {English},
  journal = {Elife},
  doi = {10.7554/elife.23383},
  author = {Nosek, Brian A. and Errington, Timothy M.},
  month = jan,
  year = {2017},
  keywords = {registered-reports,include,note},
  pages = {e23383},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\3FHM4XSP\\Nosek and Errington - 2017 - Reproducibility in Cancer Biology Making sense of.pdf},
  note = {WOS:000393400300001}
}

@article{nosek2014,
  title = {Registered {{Reports A Method}} to {{Increase}} the {{Credibility}} of {{Published Results}}},
  volume = {45},
  issn = {1864-9335},
  language = {English},
  number = {3},
  journal = {Social Psychology},
  doi = {10.1027/1864-9335/a000192},
  author = {Nosek, Brian A. and Lakens, Daniel},
  year = {2014},
  keywords = {standards,bias,science,metaanalysis,ambady,pittinsky,replication attempt,stereotype susceptibility shih,warmth,include,announcement_RRs,note},
  pages = {137-141},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\2D33R7JS\\Nosek and Lakens - 2014 - Registered Reports A Method to Increase the Credib.pdf},
  note = {WOS:000336836900001}
}

@article{nyhan2015,
  title = {Increasing the {{Credibility}} of {{Political Science Research}}: {{A Proposal}} for {{Journal Reforms}}},
  volume = {48},
  issn = {1049-0965},
  language = {English},
  journal = {Ps-Political Science \& Politics},
  doi = {10.1017/s1049096515000463},
  author = {Nyhan, Brendan},
  month = sep,
  year = {2015},
  keywords = {replication,transparency,publication bias,registered-reports,gender,medicaid,include,note},
  pages = {78-83},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\RNNRAVNE\\Nyhan - 2015 - Increasing the Credibility of Political Science Re.pdf},
  note = {WOS:000359291900014}
}

@article{olff2019,
  title = {Facts on Psychotraumatology},
  volume = {10},
  issn = {2000-8198},
  abstract = {Daily news is dominated by reports of traumatic events across the world. Is trauma indeed rather the norm than the exception? What are the facts? How can we better understand, prevent and treat the consequences of trauma? This past year the European Journal of Psychotraumatology (EJPT) has again tried to address these questions. With the gold Open Access model articles in the journal are being made immediately available without any barriers to access. In Europe, promising developments with regard to Open Science emerged in 2018, for instance, cOAlition S with their ambitious Plan S boosting the transition to full Open Access. In this editorial these and other developments in the journal, such as Registered Reports as a way to reduce Questionable Research Practices (QRPs), journal metrics, and the ESTSS EJPT award finalists for best paper of 2018 are being presented.},
  language = {English},
  number = {1},
  journal = {European Journal of Psychotraumatology},
  doi = {10.1080/20008198.2019.1578524},
  author = {Olff, Miranda},
  month = jan,
  year = {2019},
  keywords = {registered reports,impact factor,Altmetrics,Open Access,Psychotrauma,ptsd,special   issues,include,note},
  pages = {1578524},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\Z4CFGPLU\\Olff - 2019 - Facts on psychotraumatology.pdf},
  note = {WOS:000459808000001}
}

@article{parker2014,
  title = {The {{Place}} of {{Experimental Design}} and {{Statistics}} in the {{3Rs}}},
  volume = {55},
  issn = {1084-2020},
  abstract = {The 3Rs-replacement, reduction, and refinement-can be applied to any animal experiment by researchers and other bodies seeking to conduct those studies in as humane a manner as possible. Key to the success of this endeavor is an appreciation of the principles of good experimental design and analysis; these need to be considered in concert before any data is collected. Indeed, many of the principles central to helping achieve the objectives of the 3Rs-such as conducting valid, reliable, and efficient experiments; clearly and transparently reporting findings; and ensuring that an appreciation and understanding of animal welfare plays a central role in laboratory practice-are to the betterment of research per se.},
  language = {English},
  number = {3},
  journal = {Ilar Journal},
  doi = {10.1093/ilar/ilu044},
  author = {Parker, Richard M. A. and Browne, William J.},
  year = {2014},
  keywords = {statistics,science,experimental design,registered-reports,guidelines,3Rs,animal welfare,animals,laboratory animals,points,power calculations,reduction,refinement,replacement,size,welfare,include,note},
  pages = {477-485},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\ZRK2X3DN\\Parker and Browne - 2014 - The Place of Experimental Design and Statistics in.pdf},
  note = {WOS:000348058400011}
}

@article{parker2019,
  title = {Making Conservation Science More Reliable with Preregistration and Registered Reports},
  volume = {33},
  issn = {0888-8892},
  language = {English},
  number = {4},
  journal = {Conservation Biology},
  doi = {10.1111/cobi.13342},
  author = {Parker, Timothy and Fraser, Hannah and Nakagawa, Shinichi},
  month = aug,
  year = {2019},
  keywords = {include_key_has_critique},
  pages = {747-750},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\9QYJHISA\\Parker et al. - 2019 - Making conservation science more reliable with pre.pdf},
  note = {WOS:000474668700001}
}

@article{probst2015,
  title = {Advancing the {{Rigour}} and {{Integrity}} of {{Our Science}}: {{The Registered Reports Initiative}}},
  volume = {31},
  issn = {1532-3005},
  language = {English},
  number = {3},
  journal = {Stress and Health},
  doi = {10.1002/smi.2645},
  author = {Probst, Tahira M. and Hagger, Martin S.},
  month = aug,
  year = {2015},
  keywords = {include,note},
  pages = {177-179},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\FY55LZMX\\Probst and Hagger - 2015 - Advancing the Rigour and Integrity of Our Science.pdf},
  note = {WOS:000359296200001}
}

@article{przybylski2019,
  title = {Violent Video Game Engagement Is Not Associated with Adolescents' Aggressive Behaviour: Evidence from a Registered Report},
  volume = {6},
  issn = {2054-5703},
  abstract = {In this study, we investigated the extent to which adolescents who spend time playing violent video games exhibit higher levels of aggressive behaviour when compared with those who do not. A large sample of British adolescent participants (n = 1004) aged 14 and 15 years and an equal number of their carers were interviewed. Young people provided reports of their recent gaming experiences. Further, the violent contents of these games were coded using official EU and US ratings, and carers provided evaluations of their adolescents' aggressive behaviours in the past month. Following a preregistered analysis plan, multiple regression analyses tested the hypothesis that recent violent game play is linearly and positively related to carer assessments of aggressive behaviour. Results did not support this prediction, nor did they support the idea that the relationship between these factors follows a nonlinear parabolic function. There was no evidence for a critical tipping point relating violent game engagement to aggressive behaviour. Sensitivity and exploratory analyses indicated these null effects extended across multiple operationalizations of violent game engagement and when the focus was on another behavioural outcome, namely, prosocial behaviour. The discussion presents an interpretation of this pattern of effects in terms of both the ongoing scientific and policy debates around violent video games, and emerging standards for robust evidence- based policy concerning young people's technology use.},
  language = {English},
  number = {2},
  journal = {Royal Society Open Science},
  doi = {10.1098/rsos.171474},
  author = {Przybylski, Andrew K. and Weinstein, Netta},
  month = feb,
  year = {2019},
  keywords = {include,note},
  pages = {171474},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\5ML7IV6K\\Przybylski and Weinstein - 2019 - Violent video game engagement is not associated wi.pdf},
  note = {WOS:000465432900001}
}

@article{pustejovskyei2019,
  title = {Testing for Funnel Plot Asymmetry of Standardized Mean Differences},
  volume = {10},
  issn = {1759-2879},
  abstract = {Publication bias and other forms of outcome reporting bias are critical threats to the validity of findings from research syntheses. A variety of methods have been proposed for detecting selective outcome reporting in a collection of effect size estimates, including several methods based on assessment of asymmetry of funnel plots, such as the Egger's regression test, the rank correlation test, and the Trim-and-Fill test. Previous research has demonstated that the Egger's regression test is miscalibrated when applied to log-odds ratio effect size estimates, because of artifactual correlation between the effect size estimate and its standard error. This study examines similar problems that occur in meta-analyses of the standardized mean difference, a ubiquitous effect size measure in educational and psychological research. In a simulation study of standardized mean difference effect sizes, we assess the Type I error rates of conventional tests of funnel plot asymmetry, as well as the likelihood ratio test from a three-parameter selection model. Results demonstrate that the conventional tests have inflated Type I error due to the correlation between the effect size estimate and its standard error, while tests based on either a simple modification to the conventional standard error formula or a variance-stabilizing transformation both maintain close-to-nominal Type I error.},
  language = {English},
  number = {1},
  journal = {Research Synthesis Methods},
  doi = {10.1002/jrsm.1332},
  author = {Pustejovskyei, James E. and Rodgers, Melissa A.},
  month = mar,
  year = {2019},
  keywords = {publication bias,meta-analysis,registered-reports,detect publication bias,estimating effect   size,meta-regression,metaanalysis,outcome reporting bias,robust variance-estimation,self-control,standardized   mean difference,include,note},
  pages = {57-71},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\PY7NZQTS\\Pustejovskyei and Rodgers - 2019 - Testing for funnel plot asymmetry of standardized .pdf},
  note = {WOS:000461871700005}
}

@article{rapp2019,
  title = {Registered {{Reports}} in {{Discourse Processes}}},
  volume = {56},
  issn = {0163-853X},
  language = {English},
  number = {1},
  journal = {Discourse Processes},
  doi = {10.1080/0163853x.2019.1529097},
  author = {Rapp, David N.},
  month = jan,
  year = {2019},
  keywords = {include,announcement_RRs,note},
  pages = {1-1},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\CTQ2Y7UY\\Rapp - 2019 - Registered Reports in Discourse Processes.pdf},
  note = {WOS:000450458900001}
}

@article{rice2019,
  title = {Curtailing the {{Use}} of {{Preregistration}}: {{A Misused Term}}},
  issn = {1745-6916},
  abstract = {Improving the usability of psychological research has been encouraged through practices such as prospectively registering research plans. Registering research aligns with the open-science movement, as the registration of research protocols in publicly accessible domains can result in reduced research waste and increased study transparency. In medicine and psychology, two different terms, registration and preregistration, have been used to refer to study registration, but applying inconsistent terminology to represent one concept can complicate both educational outreach and epidemiological investigation. Consistently using one term across disciplines to refer to the concept of study registration may improve the understanding and uptake of this practice, thereby supporting the movement toward improving the reliability and reproducibility of research through study registration. We recommend encouraging use of the original term, registration, given its widespread and long-standing use, including in national registries.},
  language = {English},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691619858427},
  author = {Rice, Danielle B. and Moher, David},
  year = {2019},
  keywords = {preregistration,include,history_registration,trial_registration,note},
  pages = {UNSP 1745691619858427},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\QWKQZ25I\\Rice and Moher - Curtailing the Use of Preregistration A Misused T.pdf},
  note = {WOS:000483904100001}
}

@article{robertson2017,
  title = {Who Needs Registered Reports?},
  volume = {15},
  issn = {1741-7007},
  abstract = {Registered Reports, an article format initiated to help promote transparency and reproducibility in the preclinical and social sciences, are spreading into the biological literature. The format is now offered by BMC Biology, in a spirit of experiment.},
  language = {English},
  journal = {Bmc Biology},
  doi = {10.1186/s12915-017-0394-2},
  author = {Robertson, Miranda},
  month = jun,
  year = {2017},
  keywords = {include_key,empirical_case_study,announcement_RRs},
  pages = {49},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\DYX23A4J\\Robertson - 2017 - Who needs registered reports.pdf},
  note = {WOS:000403322700001}
}

@article{rothermund2018,
  title = {Three Decades of {{Cognition}} \& {{Emotion}}: {{A}} Brief Review of Past Highlights and Future Prospects},
  volume = {32},
  issn = {0269-9931},
  abstract = {Over the past three decades, Cognition \& Emotion has been one of the world's leading outlets for emotion research. In this article, we review past highlights of and future prospects for the journal. Our tour of history covers three periods: The first period, from 1987 to 1999, was a pioneering era in which cognitive theories began to be applied to the scientific analysis of emotion. The second period, from 2000 to 2007, was characterised by a sharp increase in the number of empirical research papers, a lot of which were concerned with automatic processing biases and their implications for clinical psychology. During the third period, from 2008 to 2017, a new focus emerged on self-regulatory processes and their implications for emotion. We then turn to the present profile of Cognition \& Emotion and introduce our new editorial team. Finally, we consider how the journal's future success can be continued and increased by a) providing authors with fast and high-quality feedback; b) offering attractive publication formats, including the newly introduced Registered Reports for pre-registered studies; and c) consolidating key methodological paradigms with reproducible findings.},
  language = {English},
  number = {1},
  journal = {Cognition \& Emotion},
  doi = {10.1080/02699931.2018.1418197},
  author = {Rothermund, Klaus and Koole, Sander L.},
  year = {2018},
  keywords = {psychology,disorders,psychopathology,affective processing biases,anxiety,appraisal,basic emotions,cognition and emotion,cognitive theories of emotion,emotion regulation,Historical review,life,memory,perspectives,registered replication report,special-issue,include,note},
  pages = {1-12},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\2QUEZTZ5\\Rothermund and Koole - 2018 - Three decades of Cognition & Emotion A brief revi.pdf},
  note = {WOS:000424988300001}
}

@article{rotteveel2015,
  title = {On the Automatic Link between Affect and Tendencies to Approach and Avoid: {{Chen}} and {{Bargh}} (1999) Revisited},
  volume = {6},
  issn = {1664-1078},
  abstract = {Within the literature on emotion and behavioral action, studies on approach-avoidance take up a prominent place. Several experimental paradigms feature successful conceptual replications but many original studies have not yet been replicated directly. We present such a direct replication attempt of two seminal experiments originally conducted by Chen and Bargh (1999). In their first experiment, participants effectively evaluated attitude objects by pulling or pushing a lever. Participants who had to pull the lever with positively valenced attitude objects and push the lever with negatively valenced attitude objects (i.e., congruent instruction) did so faster than participants who had to follow the reverse (i.e., incongruent) instruction. In Chen and Bargh's second experiment, the explicit evaluative instructions were absent and participants merely responded to the attitude objects by either always pushing or always pulling the lever. Similar results were obtained as in Experiment 1. Based on these findings, Chen and Bargh concluded that (1) attitude objects are evaluated automatically; and (2) attitude objects automatically trigger a behavioral tendency to approach or avoid. We attempted to replicate both experiments and failed to find the effects reported by Chen and Bargh as indicated by our pre-registered Bayesian data analyses; nevertheless, the evidence in favor of the null hypotheses was only anecdotal, and definitive conclusions await further study.},
  language = {English},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2015.00335},
  author = {Rotteveel, Mark and Gierholz, Alexander and Koch, Gijs and {van Aalst}, Cherelle and Pinto, Yair and Matzke, Dora and Steingroever, Helen and Verhagen, Josine and Beek, Titia F. and Selker, Ravi and Sasiadek, Adam and Wagenmakers, Eric-Jan},
  month = apr,
  year = {2015},
  keywords = {replication,registered-reports,crisis,hypothesis,affect,approach,avoidance,default bayes factors,emotion,generality,predispositions,include,note},
  pages = {335},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\TFDIVB2R\\Rotteveel et al. - 2015 - On the automatic link between affect and tendencie.pdf},
  note = {WOS:000352203900001}
}

@article{shaw2019,
  title = {Registered {{Reports}}, {{Replication}}, and the {{Canadian Journal}} of {{School Psychology}}: {{Improving}} the {{Evidence}} in {{Evidence}}-{{Based School Psychology}}},
  volume = {34},
  issn = {0829-5735},
  abstract = {The Canadian Journal of School Psychology (CJSP) is offering scholars the opportunity to register research reports and make research protocols publicly available to promote replication, transparency, credibility, and utility for clinical practice. The purpose of this article is to outline the challenges regarding replication, reproducibility, and evidence-based practices, as well as describe the submission protocol and criteria for acceptance of registered reports. Advances and criticisms of the registered reports model are discussed. Although CJSP will accept submissions through the traditional peer-review model, registered reports and support of replication studies have the objective of promoting high-quality research to improve the research foundation for evidence-based practices in the profession of school psychology.},
  language = {English},
  number = {3},
  journal = {Canadian Journal of School Psychology},
  doi = {10.1177/0829573519843027},
  author = {Shaw, Steven R. and D'Intino, Joseph S. and Lysenko, Ekaterina},
  month = sep,
  year = {2019},
  keywords = {publication bias,incentives,editorial,crisis,evidence-based interventions,improving research,registered   reports,replications,announcement_RRs,include_key_has_critique},
  pages = {175-187},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\D9I3IRIW\\Shaw et al. - 2019 - Registered Reports, Replication, and the Canadian .pdf},
  note = {WOS:000479292700001}
}

@article{smith2019,
  title = {Enhancing Research Integrity in Academic Nursing: {{The}} Introduction of Registered Reports},
  volume = {28},
  issn = {0962-1067},
  language = {English},
  number = {7-8},
  journal = {Journal of Clinical Nursing},
  doi = {10.1111/jocn.14770},
  author = {Smith, Graeme D. and Penny, Kay I.},
  month = apr,
  year = {2019},
  keywords = {include,announcement_RRs,note},
  pages = {1037-1038},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\LJR96M9A\\Smith and Penny - 2019 - Enhancing research integrity in academic nursing .pdf},
  note = {WOS:000460767400001}
}

@article{spiller2018,
  title = {Reducing Uncertainty in Research: Introducing Registered Reports},
  volume = {9},
  issn = {2000-8066},
  language = {English},
  number = {1},
  journal = {European Journal of Psychotraumatology},
  doi = {10.1080/20008198.2018.1554417},
  author = {Spiller, Tobias R. and Olff, Miranda},
  month = dec,
  year = {2018},
  keywords = {include_key_has_critique},
  pages = {1554417},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\PLHPH525\\Spiller and Olff - 2018 - Reducing uncertainty in research introducing regi.pdf},
  note = {WOS:000453713200001}
}

@article{syed2018,
  title = {Open {{Science Initiatives}} at {{Emerging Adulthood}}},
  volume = {6},
  issn = {2167-6968},
  abstract = {This editorial reports on concrete changes in expectations and practices at Emerging Adulthood that are effective immediately. These include: aligning with Level 1 of the Transparency and Openness Promotion (TOP) Guidelines, adding Registered Reports as a submission option, accepting commentaries on articles published in any journal, and making open science badges available to authors.},
  language = {English},
  number = {6},
  journal = {Emerging Adulthood},
  doi = {10.1177/2167696818810103},
  author = {Syed, Moin},
  month = dec,
  year = {2018},
  keywords = {include,RRs,announcement_RRs,note},
  pages = {371-374},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\2UN2TUHR\\Syed - 2018 - Open Science Initiatives at Emerging Adulthood.pdf},
  note = {WOS:000450024100001}
}

@article{tibon2018,
  title = {Title {{TBA}}: {{Revising}} the {{Abstract Submission Process}}},
  volume = {22},
  issn = {1364-6613},
  abstract = {Academic conferences are among the most prolific scientific activities, yet the current abstract submission and review process has serious limitations. We propose a revised process that would address these limitations, achieve some of the aims of Open Science, and stimulate discussion throughout the entire lifecycle of the scientific work.},
  language = {English},
  number = {4},
  journal = {Trends in Cognitive Sciences},
  doi = {10.1016/j.tics.2018.01.008},
  author = {Tibon, Roni and Henson, Richard},
  month = apr,
  year = {2018},
  keywords = {registered-reports,include,note},
  pages = {271-274},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\BN4VQ5N4\\Tibon and Henson - 2018 - Title TBA Revising the Abstract Submission Proces.pdf},
  note = {WOS:000428013800001}
}

@article{uhlmann2019,
  title = {Scientific {{Utopia III}}: {{Crowdsourcing Science}}},
  volume = {14},
  issn = {1745-6916},
  abstract = {Most scientific research is conducted by small teams of investigators who together formulate hypotheses, collect data, conduct analyses, and report novel findings. These teams operate independently as vertically integrated silos. Here we argue that scientific research that is horizontally distributed can provide substantial complementary value, aiming to maximize available resources, promote inclusiveness and transparency, and increase rigor and reliability. This alternative approach enables researchers to tackle ambitious projects that would not be possible under the standard model. Crowdsourced scientific initiatives vary in the degree of communication between project members from largely independent work curated by a coordination team to crowd collaboration on shared activities. The potential benefits and challenges of large-scale collaboration span the entire research process: ideation, study design, data collection, data analysis, reporting, and peer review. Complementing traditional small science with crowdsourced approaches can accelerate the progress of science and improve the quality of scientific research.},
  language = {English},
  number = {5},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691619850561},
  author = {Uhlmann, Eric Luis and Ebersole, Charles R. and Chartier, Sage Christopher R. and Errington, Timothy M. and Kidwell, Mallory C. and Lai, Calvin K. and McCarthy, Randy J. and Riegelman, Amy and Silberzahn, Raphael and Nosek, Brian A.},
  month = sep,
  year = {2019},
  keywords = {replication,reproducibility,methodology,power,replicability,reliability,collaboration,crowdsourcing,metascience,teams,impact factor,quality,registered-reports,social-psychology,validity,include,note},
  pages = {711-733},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\6X5SDXCF\\Uhlmann et al. - 2019 - Scientific Utopia III Crowdsourcing Science.pdf},
  note = {WOS:000485322100001}
}

@article{vantveer2016,
  title = {Pre-Registration in Social Psychology-{{A}} Discussion and Suggested Template},
  volume = {67},
  issn = {0022-1031},
  abstract = {Pre-registration of studies before they are conducted has recently become more feasible for researchers, and is encouraged by an increasing number of journals. However, because the practice of pre-registration is relatively new to psychological science, specific guidelines for the content of registrations are still in a formative stage. After giving a brief history of pre-registration in medical and psychological research, we outline two different models that can be applied reviewed and unreviewed pre-registration and discuss the advantages of each model to science as a whole and to.the individual scientist, as well as some of their drawbacks and limitations. Finally, we present and justify a proposed standard template that can facilitate pre-registration. Researchers can use the template before and during the editorial process to meet article requirements and enhance the robustness of their scholarly efforts. (C) 2016 Elsevier Inc. All rights reserved.},
  language = {English},
  journal = {Journal of Experimental Social Psychology},
  doi = {10.1016/j.jesp.2016.03.004},
  author = {{van 't Veer}, Anna Elisabeth and {Giner-Sorolla}, Roger},
  month = nov,
  year = {2016},
  keywords = {include_key_has_critique},
  pages = {2-12},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\NSXPLRSH\\van 't Veer and Giner-Sorolla - 2016 - Pre-registration in social psychology-A discussion.pdf},
  note = {WOS:000384398700002}
}

@article{vandick2015,
  title = {Registered {{Reports}}, {{Advance Articles Online}}, and the {{Way Ahead}}},
  volume = {14},
  issn = {1866-5888},
  language = {English},
  number = {1},
  journal = {Journal of Personnel Psychology},
  doi = {10.1027/1866-5888/a000140},
  author = {{van Dick}, Rolf},
  year = {2015},
  keywords = {include,note},
  pages = {1-3},
  note = {WOS:000356028700001}
}

@article{vantveer2015,
  title = {Unconscious Deception Detection Measured by Finger Skin Temperature and Indirect Veracity Judgments-Results of a Registered Report},
  volume = {6},
  issn = {1664-1078},
  abstract = {A pre-registered experiment was conducted to examine psychophysiological responses to being lied to. Bridging research on social cognition and deception detection, we hypothesized that observing a liar compared to a truth-teller would decrease finger skin temperature of observers. Participants first watched two targets while not forewarned that they would later be asked to judge (direct and indirect) veracity, and then watched another two targets while forewarned about this. During both these phases finger skin temperature was measured. Findings pertaining to temperature partly confirmed our main hypothesis. When participants were observing a liar, irrespective of being forewarned, on average finger skin temperature declined over time. In the forewarned phase, temperature trajectories of truth-tellers were higher than those of liars, however, in the not forewarned phase, this pattern was reversed. Results confirmed our further hypotheses that participants judge liars as less likeable and less trustworthy than truth-tellers an indication of indirect deception detection. Our hypothesis that the effect size for trustworthiness would be bigger than that of liking was not supported by the data. Additionally, and also confirming our hypothesis, participants performed around chance level when directly judging whether the target person was lying. Exploratory analyses are reported with regard to truth bias and dependency between direct and indirect veracity judgments. Limitations and directions for future work related to the existence of psychophysiological indicators of deception detection are discussed.},
  language = {English},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2015.00672},
  author = {{van't Veer}, Anna E. and Gallucci, Marcello and Stel, Marielle and {van Beest}, Ilja},
  month = jun,
  year = {2015},
  keywords = {accuracy,beliefs,cold,deception detection,indirect   deception detection,interpersonal relations,multilevel models,physiological markers,psychophysiology,skin temperature,include,note,empirical_RR},
  pages = {672},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\F8MMXPP2\\van't Veer et al. - 2015 - Unconscious deception detection measured by finger.pdf},
  note = {WOS:000356046000001}
}

@article{ware2015,
  title = {Significance Chasing in Research Practice: Causes, Consequences and Possible Solutions},
  volume = {110},
  issn = {0965-2140},
  abstract = {Background and AimsThe low reproducibility of findings within the scientific literature is a growing concern. This may be due to many findings being false positives which, in turn, can misdirect research effort and waste money. MethodsWe review factors that may contribute to poor study reproducibility and an excess of significant' findings within the published literature. Specifically, we consider the influence of current incentive structures and the impact of these on research practices. ResultsThe prevalence of false positives within the literature may be attributable to a number of questionable research practices, ranging from the relatively innocent and minor (e.g. unplanned post-hoc tests) to the calculated and serious (e.g. fabrication of data). These practices may be driven by current incentive structures (e.g. pressure to publish), alongside the preferential emphasis placed by journals on novelty over veracity. There are a number of potential solutions to poor reproducibility, such as new publishing formats that emphasize the research question and study design, rather than the results obtained. This has the potential to minimize significance chasing and non-publication of null findings. ConclusionsSignificance chasing, questionable research practices and poor study reproducibility are the unfortunate consequence of a publish or perish' culture and a preference among journals for novel findings. It is likely that top-down change implemented by those with the ability to modify current incentive structure (e.g. funders and journals) will be required to address problems of poor reproducibility.},
  language = {English},
  number = {1},
  journal = {Addiction},
  doi = {10.1111/add.12673},
  author = {Ware, Jennifer J. and Munafo, Marcus R.},
  month = jan,
  year = {2015},
  keywords = {reproducibility,publication bias,bias,incentives,reliability,science,statistical power,fraud,False positive,impact,registered-reports,false,pre-registration,genetic association,persistence,significance chasing,include,note},
  pages = {4-8},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\AXRNZQBS\\Ware and Munafo - 2015 - Significance chasing in research practice causes,.pdf},
  note = {WOS:000346699700002}
}

@article{weinhardt2019,
  title = {Introducing {{Registered Reports}} to the {{Information Systems Community}}},
  volume = {61},
  issn = {2363-7005},
  language = {English},
  number = {4},
  journal = {Business \& Information Systems Engineering},
  doi = {10.1007/s12599-019-00602-6},
  author = {Weinhardt, Christof and {van der Aalst}, Wil M. P. and Hinz, Oliver},
  month = aug,
  year = {2019},
  keywords = {reproducibility,announcement_RRs,include_key_has_critique},
  pages = {381-384},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\WTGYEYWU\\Weinhardt et al. - 2019 - Introducing Registered Reports to the Information .pdf},
  note = {WOS:000476549800001}
}

@article{wessel2019,
  title = {We Need to Change Our Attitude, and Journals Can Help: {{Reflections}} in Response to {{Spiller}} \& {{Olff}} (2018)},
  volume = {10},
  issn = {2000-8198},
  abstract = {Adopting Registered Reports is an important step for the European Journal of Psychotraumatology to promote open science practices in the field of psychotrauma research. However, adopting these practices requires us as individual researchers to change our perspective fundamentally. We need to put fears of being scooped aside, adopt a permissive stance towards making mistakes and accept that null-results should be part of the scientific record. This is difficult because the culture in academia is competitive. Incentives are on publishing novel and positive results in high impact journals. A change in journal policies, such that openness and transparency are reinforced, can facilitate an attitude change in individual researchers.},
  language = {English},
  number = {1},
  journal = {European Journal of Psychotraumatology},
  doi = {10.1080/20008198.2019.1614823},
  author = {Wessel, Ineke and Niemeyer, Helen},
  month = jan,
  year = {2019},
  keywords = {open science,replication crisis,Registered reports,include_key},
  pages = {1614823},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\L9NU97GZ\\Wessel and Niemeyer - 2019 - We need to change our attitude, and journals can h.pdf},
  note = {WOS:000467710600001}
}

@article{wicherts2017,
  title = {The {{Weak Spots}} in {{Contemporary Science}} (and {{How}} to {{Fix Them}})},
  volume = {7},
  issn = {2076-2615},
  abstract = {Simple Summary Several fraud cases, widespread failure to replicate or reproduce seminal findings, and pervasive error in the scientific literature have led to a crisis of confidence in the biomedical, behavioral, and social sciences. In this review, the author discusses some of the core findings that point at weak spots in contemporary science and considers the human factors that underlie them. He delves into the human tendencies that create errors and biases in data collection, analyses, and reporting of research results. He presents several solutions to deal with observer bias, publication bias, the researcher's tendency to exploit degrees of freedom in their analysis of data, low statistical power, and errors in the reporting of results, with a focus on the specific challenges in animal welfare research. Abstract In this review, the author discusses several of the weak spots in contemporary science, including scientific misconduct, the problems of post hoc hypothesizing (HARKing), outcome switching, theoretical bloopers in formulating research questions and hypotheses, selective reading of the literature, selective citing of previous results, improper blinding and other design failures, p-hacking or researchers' tendency to analyze data in many different ways to find positive (typically significant) results, errors and biases in the reporting of results, and publication bias. The author presents some empirical results highlighting problems that lower the trustworthiness of reported results in scientific literatures, including that of animal welfare studies. Some of the underlying causes of these biases are discussed based on the notion that researchers are only human and hence are not immune to confirmation bias, hindsight bias, and minor ethical transgressions. The author discusses solutions in the form of enhanced transparency, sharing of data and materials, (post-publication) peer review, pre-registration, registered reports, improved training, reporting guidelines, replication, dealing with publication bias, alternative inferential techniques, power, and other statistical tools.},
  language = {English},
  number = {12},
  journal = {Animals},
  doi = {10.3390/ani7120090},
  author = {Wicherts, Jelte M.},
  month = dec,
  year = {2017},
  keywords = {reproducibility,publication bias,confirmation bias,psychology,replicability,p-values,meta-research,registered-reports,validity,clinical-trials,randomized controlled-trials,recommendations,citation bias,consort   statement,questionable research   practices,include,note},
  pages = {90},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\BBRWPKNC\\Wicherts - 2017 - The Weak Spots in Contemporary Science (and How to.pdf},
  note = {WOS:000419173100004}
}

@article{wilkinson2019,
  title = {Registered Reports: Prospective Peer Review Emphasizes Science over Spin},
  volume = {111},
  issn = {0015-0282},
  language = {English},
  number = {5},
  journal = {Fertility and Sterility},
  doi = {10.1016/j.fertnstert.2019.03.010},
  author = {Wilkinson, Jack and Pellicer, Antonio and Niederberger, Craig},
  month = may,
  year = {2019},
  keywords = {include,announcement_RRs,note},
  pages = {831-832},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\TXQD5DEJ\\Wilkinson et al. - 2019 - Registered reports prospective peer review emphas.pdf},
  note = {WOS:000465563900001}
}

@article{wiseman2019,
  title = {Registered Reports: An Early Example an Analysis},
  volume = {7},
  issn = {2167-8359},
  abstract = {The recent 'replication crisis' in psychology has focused attention on ways of increasing methodological rigor within the behavioral sciences. Part of this work has involved promoting 'Registered Reports', wherein journals peer review papers prior to data collection and publication. Although this approach is usually seen as a relatively recent development, we note that a prototype of this publishing model was initiated in the mid-1970s by parapsychologist Martin Johnson in the European Journal of Parapsychology (EJP). A retrospective and observational comparison of Registered and non-Registered Reports published in the EJP during a seventeen-year period provides circumstantial evidence to suggest that the approach helped to reduce questionable research practices. This paper aims both to bring Johnson's pioneering work to a wider audience, and to investigate the positive role that Registered Reports may play in helping to promote higher methodological and statistical standards.},
  language = {English},
  journal = {Peerj},
  doi = {10.7717/peerj.6232},
  author = {Wiseman, Richard and Watt, Caroline and Kornbrot, Diana},
  month = jan,
  year = {2019},
  keywords = {empirical,include_key},
  pages = {e6232},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\N9AJRMJA\\Wiseman et al. - 2019 - Registered reports an early example an analysis.pdf},
  note = {WOS:000455766400002}
}

@article{woznyj2018,
  title = {Results-Blind Review: A Masked Crusader for Science},
  volume = {27},
  issn = {1359-432X},
  abstract = {The organizational sciences are entering a confidence crisis where a growing number of scholars recognize our science is imperfect and our knowledge base is potentially flawed. One contributing factor that scholars have identified is the peer-review process; issues such as QRPs, positive outcome biases and publication bias are, in part, a product of the traditional peer-review process and contribute to the questionable credibility of our science. The current paper focuses on the results-blind review as a solution to improve the existing system because it has received little attention yet fits well with the nature of our discipline (e.g., not entirely grant-funded, field-research oriented). Using a mixed-methods approach, we surveyed 203 editorial board members to understand the scientific community's reactions to the results-blind review initiative and readiness to implement change. Our results suggest that there are noted advantages of the results-blind review process and the scientific community is open to the initiative in our field. However, our data also suggest that there may be some hesitations about the initiative, particularly with implementing a new review process. Based on the results, we offer actionable recommendations for authors, reviewers, and editors regarding the results-blind review.},
  language = {English},
  number = {5},
  journal = {European Journal of Work and Organizational Psychology},
  doi = {10.1080/1359432x.2018.1496081},
  author = {Woznyj, Haley M. and Grenier, Kelcie and Ross, Roxanne and Banks, George C. and Rogelberg, Steven G.},
  year = {2018},
  keywords = {empirical,include},
  pages = {561-576},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\4NFJKIDH\\Woznyj et al. - 2018 - Results-blind review a masked crusader for scienc.pdf},
  note = {WOS:000445869200008}
}

@article{zwaan2018,
  title = {Making Replication Mainstream},
  volume = {41},
  issn = {0140-525X},
  abstract = {Many philosophers of science and methodologists have argued that the ability to repeat studies and obtain similar results is an essential component of science. A finding is elevated from single observation to scientific evidence when the procedures that were used to obtain it can be reproduced and the finding itself can be replicated. Recent replication attempts show that some high profile results - most notably in psychology, but in many other disciplines as well - cannot be replicated consistently. These replication attempts have generated a considerable amount of controversy, and the issue of whether direct replications have value has, in particular, proven to be contentious. However, much of this discussion has occurred in published commentaries and social media outlets, resulting in a fragmented discourse. To address the need for an integrative summary, we review various types of replication studies and then discuss the most commonly voiced concerns about direct replication. We provide detailed responses to these concerns and consider different statistical ways to evaluate replications. We conclude there are no theoretical or statistical obstacles to making direct replication a routine aspect of psychological science.},
  language = {English},
  journal = {Behavioral and Brain Sciences},
  doi = {10.1017/s0140525x17001972},
  author = {Zwaan, Rolf A. and Etz, Alexander and Lucas, Richard E. and Donnellan, M. Brent},
  year = {2018},
  keywords = {replication,reproducibility,publication bias,replicability,psychological research,registered-reports,psychological science,statistical   significance,ego-depletion,improving written communication,multilab preregistered replication,research programs,tests,traveling-waves,include,note},
  pages = {e120},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\GK2M9KV5\\Zwaan et al. - 2018 - Making replication mainstream.pdf},
  note = {WOS:000458790700035}
}

@article{chambers2014,
  title = {Instead of ``Playing the Game'' It Is Time to Change the Rules: {{Registered Reports}} at {{AIMS Neuroscience}} and Beyond},
  volume = {1},
  issn = {2373-7972},
  shorttitle = {Instead of ``Playing the Game'' It Is Time to Change the Rules},
  language = {en},
  number = {1},
  journal = {AIMS Neuroscience},
  doi = {10.3934/Neuroscience.2014.1.4},
  author = {Chambers, Christopher and Feredoes, Eva and Muthukumaraswamy, Suresh and Etchells, Peter},
  year = {2014},
  keywords = {announcement_RRs,include_referenced},
  pages = {4-17},
  file = {C\:\\Users\\zn18986\\Zotero\\storage\\7X757QIG\\D. Chambers et al. - 2014 - Instead of “playing the game” it is time to change.pdf},
  note = {ZSCC: NoCitationData[s0]}
}


