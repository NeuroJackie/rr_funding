---
title: "Interpretation"
author: "Katie Drax"
date: "7 November 2019"
output: 
  pdf_document:
    latex_engine: pdflatex
    number_sections: true
    fig_caption: true
---

```{r setup, include=F} 
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)

library(tidyverse)
library(knitr)
library(pander)
library(tidytext)

#replace pandoc_table(...) with kable() if exporting word document

### 
# import data ####
#####

no_note <- read_csv("../mini_review/data/analysis_not_noted.csv", trim_ws = T)
note <- read_csv("../mini_review/data/analysis_noted.csv", trim_ws = T)

df <- rbind(note, no_note)

citekey <- read_csv("../mini_review/data/inc_citekeys.csv") %>%
  select(c("Title", "Citekey"))

colnames(citekey) <- tolower(colnames(citekey))

df <- full_join(df, citekey, by = "title")


#########################
# Separate empirical_pro #### 
##################

# separate

nmax <- max(str_count(df$empirical_pro, ";"), na.rm = T) + 1

df <- separate(df, empirical_pro, into = paste0("empirical_pro", seq_len(nmax)), sep = ";", fill = "warn") 

# Transform team members into columns

df <-  gather(df,  key= "num", value = "empirical_pro", contains("empirical_pro"), na.rm = F)

# drop num col

df$num <- NULL

# remove duplicated rows

df <- df[!duplicated(df), ]
#########################
# Separate empirical_con #### 
##################

# separate

nmax <- max(str_count(df$empirical_con, ";"), na.rm = T) + 1

df <- separate(df, empirical_con, into = paste0("empirical_con", seq_len(nmax)), sep = ";", fill = "warn") 


# Transform team members into columns

df <-  gather(df,  key= "num", value = "empirical_con", contains("empirical_con"), na.rm = F)

# drop member_num col

df$num <- NULL

# remove duplicated rows

df <- df[!duplicated(df), ]
#########################
# Separate opinion_pro #### 
##################

nmax <- max(str_count(df$opinion_pro, ";"), na.rm = T) + 1

df <- separate(df, opinion_pro, into = paste0("opinion_pro", seq_len(nmax)), sep = ";", fill = "warn") 

# Transform team members into columns

df <-  gather(df,  key= "num", value = "opinion_pro", contains("opinion_pro"), na.rm = F)

# drop member_num col

df$num <- NULL

# remove duplicated rows

df <- df[!duplicated(df), ]
#####################
# separate  ###
#########################

# separate opinion_con_buts (correct mispelling in separed cols)

nmax <- max(str_count(df$opinion_con_buts, ";"), na.rm = T) + 1

df <- separate(df, opinion_con_buts, into = paste0("opinion_con_buts", seq_len(nmax)), sep = ";", fill = "warn")

# Transform team members into columns

df <-  gather(df,  key= "num", value = "opinion_con_buts", contains("opinion_con_buts"), na.rm = F)

# drop member_num col

df$num <- NULL

# remove duplicated rows

df <- df[!duplicated(df), ]

# trim whitespace

df <- lapply(df, function(x) gsub("[^\u0001-\u007F]+", "",x)) %>%
  lapply(function(x) gsub("\t\n\r\v\f", "",x)) %>%
  as.data.frame(stringsAsFactors = F)

# relabel NAs

df[df == c(" ", "")] <- NA

################
# functions ####
#################

# having separate col values for grep & select functions is simplest way
tab <-function(pattern, grep_col, col) {
  # subset df conditioned on pattern match in a column
  df[grepl(pattern, grep_col, ignore.case = T), ] %>%
    # only need citekey & column to locate string
    select(c("citekey", col)) %>%
    # using gather function creates alot of duplication = need to remove them
    .[!duplicated(.), ] %>% 
    # select complete cases to prevent NAs appearing in table
    .[complete.cases(.), ]%>%
    # sort by citekey
    arrange(citekey) %>%
    # split. functions ensure table is width of page
    pandoc.table(split.cell= 80, split.table = Inf)
}


neg_tab <-function(pattern, grep_col, col) {
  df[!grepl(pattern, grep_col, ignore.case = T), ] %>%
    select(c("citekey", col)) %>%
    .[!duplicated(.), ] %>% 
    .[complete.cases(.), ] %>%
    arrange(citekey) %>%
    pandoc.table(split.cell= 80, split.table = Inf)
}

df_subset <- function(df, col){
  select(df, c("citekey", col)) %>%
    .[!duplicated(.), ] %>% 
    .[complete.cases(.), ] %>%
    arrange(citekey)
}

# subset df and conduct content analysis
# df[grep("IPA", df$opinion_pro, ignore.case = T), ] %>%
  #df_subset("opinion_pro") %>%
  #unnest_tokens(output = word, input = opinion_pro)%>%
  #anti_join(stop_words)%>%
  #mutate(word = SnowballC::wordStem(word)) %>%
  #count(word, sort = T)

```


# IPA benefits

```{r}
tab("ipa", df$opinion_pro, "opinion_pro")


```

\pagebreak

#IPA cons & buts

```{r}
tab("ipa", df$opinion_con_buts, "opinion_con_buts")


```

\pagebreak

# Benefits of pre-study review

```{r}

tab("pre-study|feedback", df$opinion_pro, "opinion_pro")

```

\pagebreak

# Cons & buts pre-study review

```{r}
tab("pre-study|feedback", df$opinion_con_buts, "opinion_con_buts")

```

\pagebreak

# Other pros

```{r}
neg_tab("ipa|feedback|pre-study", df$opinion_pro, "opinion_pro")
```

\pagebreak

# Other cons & buts

```{r}
neg_tab("ipa|feedback|pre-study", df$opinion_con_buts, "opinion_con_buts")
```

\pagebreak

# Empirical evidence IPA

```{r}

tab("ipa", df$empirical_pro, "empirical_pro")
tab("ipa", df$empirical_con, "empirical_con")
```

\pagebreak

# Empirical evidence pre-study review

```{r}
tab("pre-study|feedback", df$empirical_pro, "empirical_pro")
tab("pre-study|feedback", df$empirical_con, "empirical_con")
```

\pagebreak

# Empirical evidence other

```{r}
neg_tab("ipa|feedback|pre-study", df$empirical_pro, "empirical_pro")
neg_tab("ipa|feedback|pre-study", df$empirical_con, "empirical_con")

```
